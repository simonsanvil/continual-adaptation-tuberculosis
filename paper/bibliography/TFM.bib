@article{adaimiLifelongAdaptiveMachine2022,
  title = {Lifelong {{Adaptive Machine Learning}} for {{Sensor-Based Human Activity Recognition Using Prototypical Networks}}},
  author = {Adaimi, Rebecca and Thomaz, Edison},
  year = {2022},
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {18},
  pages = {6881},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s22186881},
  urldate = {2023-08-27},
  abstract = {Continual learning (CL), also known as lifelong learning, is an emerging research topic that has been attracting increasing interest in the field of machine learning. With human activity recognition (HAR) playing a key role in enabling numerous real-world applications, an essential step towards the long-term deployment of such systems is to extend the activity model to dynamically adapt to changes in people's everyday behavior. Current research in CL applied to the HAR domain is still under-explored with researchers exploring existing methods developed for computer vision in HAR. Moreover, analysis has so far focused on task-incremental or class-incremental learning paradigms where task boundaries are known. This impedes the applicability of such methods for real-world systems. To push this field forward, we build on recent advances in the area of continual learning and design a lifelong adaptive learning framework using Prototypical Networks, LAPNet-HAR, that processes sensor-based data streams in a task-free data-incremental fashion and mitigates catastrophic forgetting using experience replay and continual prototype adaptation. Online learning is further facilitated using contrastive loss to enforce inter-class separation. LAPNet-HAR is evaluated on five publicly available activity datasets in terms of its ability to acquire new information while preserving previous knowledge. Our extensive empirical results demonstrate the effectiveness of LAPNet-HAR in task-free CL and uncover useful insights for future challenges.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {catastrophic forgetting,continual learning,human activity recognition,incremental learning,intransigence,lifelong learning,online learning,prototypical networks,task-free},
  file = {/Users/simon/Zotero/storage/GYTXM4WF/Adaimi and Thomaz - 2022 - Lifelong Adaptive Machine Learning for Sensor-Base.pdf}
}

@article{adaimiLifelongAdaptiveMachine2022a,
  title = {Lifelong {{Adaptive Machine Learning}} for {{Sensor-Based Human Activity Recognition Using Prototypical Networks}}},
  author = {Adaimi, Rebecca and Thomaz, Edison},
  year = {2022},
  month = jan,
  journal = {Sensors},
  volume = {22},
  number = {18},
  pages = {6881},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s22186881},
  urldate = {2023-08-30},
  abstract = {Continual learning (CL), also known as lifelong learning, is an emerging research topic that has been attracting increasing interest in the field of machine learning. With human activity recognition (HAR) playing a key role in enabling numerous real-world applications, an essential step towards the long-term deployment of such systems is to extend the activity model to dynamically adapt to changes in people's everyday behavior. Current research in CL applied to the HAR domain is still under-explored with researchers exploring existing methods developed for computer vision in HAR. Moreover, analysis has so far focused on task-incremental or class-incremental learning paradigms where task boundaries are known. This impedes the applicability of such methods for real-world systems. To push this field forward, we build on recent advances in the area of continual learning and design a lifelong adaptive learning framework using Prototypical Networks, LAPNet-HAR, that processes sensor-based data streams in a task-free data-incremental fashion and mitigates catastrophic forgetting using experience replay and continual prototype adaptation. Online learning is further facilitated using contrastive loss to enforce inter-class separation. LAPNet-HAR is evaluated on five publicly available activity datasets in terms of its ability to acquire new information while preserving previous knowledge. Our extensive empirical results demonstrate the effectiveness of LAPNet-HAR in task-free CL and uncover useful insights for future challenges.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {catastrophic forgetting,continual learning,human activity recognition,incremental learning,intransigence,lifelong learning,online learning,prototypical networks,task-free},
  file = {/Users/simon/Zotero/storage/ZQU9BFF4/Adaimi and Thomaz - 2022 - Lifelong Adaptive Machine Learning for Sensor-Base.pdf}
}

@inproceedings{ahmadGeneticAlgorithmArtificialNeural2010,
  title = {Genetic {{Algorithm-Artificial Neural Network}} ({{GA-ANN}}) {{Hybrid Intelligence}} for {{Cancer Diagnosis}}},
  booktitle = {2010 2nd {{International Conference}} on {{Computational Intelligence}}, {{Communication Systems}} and {{Networks}}},
  author = {Ahmad, Fadzil and {Mat-Isa}, Nor Ashidi and Hussain, Zakaria and Boudville, Rozan and Osman, Muhammad Khusairi},
  year = {2010},
  month = jul,
  pages = {78--83},
  doi = {10.1109/CICSyN.2010.46},
  abstract = {Artificial Neural Network (ANN) is one of the most promising biological inspired computational intelligence techniques. However designing an ANN is a difficult task as it requires setting of ANN structure and tuning of some complex parameter. On the other hand, Genetic Algorithm (GA) as a global search technique is useful for complex optimization problem where the numbers of parameters are large and difficult to obtain. In this paper GA has been used to simultaneously select significant features as input to ANN and automatically determine the optimal number of hidden node. Meanwhile the ANN training is done by Levenberg Marquardt (LM) algorithm. A new procedure in obtaining optimal ANN architecture is also described which based on feature importance determine by Genetic Algorithm. Simulation results on cancer dataset proved that the proposed method has achieved the highest 97\% average percentage of correct classification with the absent of 2nd and 5th feature.},
  keywords = {Accuracy,Artificial Neural Network,Artificial neural networks,Biological cells,Cancer,Computational Intelligence,Feature Selection and Hidden Node Optimization,Gallium,Genetic Algorithm,Optimization,Training}
}

@misc{AIRadCompanion,
  type = {Text},
  title = {{{AI-Rad Companion}}},
  urldate = {2023-08-26},
  abstract = {AI-Rad Companion automatically performs measurements and prepares results in the form of clinical images and reports.},
  copyright = {2023},
  howpublished = {https://www.siemens-healthineers.com/digital-health-solutions/ai-rad-companion},
  langid = {english},
  file = {/Users/simon/Zotero/storage/5AB4Q8CD/ai-rad-companion.html}
}

@inproceedings{alayracAreLabelsRequired2019,
  title = {Are {{Labels Required}} for {{Improving Adversarial Robustness}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Alayrac, Jean-Baptiste and Uesato, Jonathan and Huang, Po-Sen and Fawzi, Alhussein and Stanforth, Robert and Kohli, Pushmeet},
  year = {2019},
  volume = {32},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-04-23},
  abstract = {Recent work has uncovered the interesting (and somewhat surprising) finding that training models to be invariant to adversarial perturbations requires substantially larger datasets than those required for standard classification. This result is a key hurdle in the deployment of robust machine learning models in many real world applications where labeled data is expensive. Our main insight is that unlabeled data can be a competitive alternative to labeled data for training adversarially robust models. Theoretically, we show that in a simple statistical setting, the sample complexity for learning an adversarially robust model from unlabeled data matches the fully supervised case up to constant factors. On standard datasets like CIFAR- 10, a simple Unsupervised Adversarial Training (UAT) approach using unlabeled data improves robust accuracy by 21.7\% over using 4K supervised examples alone, and captures over 95\% of the improvement from the same number of labeled examples. Finally, we report an improvement of 4\% over the previous state-of-the- art on CIFAR-10 against the strongest known attack by using additional unlabeled data from the uncurated 80 Million Tiny Images dataset. This demonstrates that our finding extends as well to the more realistic case where unlabeled data is also uncurated, therefore opening a new avenue for improving adversarial training.},
  file = {/Users/simon/Zotero/storage/96W9GULA/Alayrac et al. - 2019 - Are Labels Required for Improving Adversarial Robu.pdf}
}

@article{anguitaQuantumOptimizationTraining2003,
  title = {Quantum Optimization for Training Support Vector Machines},
  author = {Anguita, Davide and Ridella, Sandro and Rivieccio, Fabio and Zunino, Rodolfo},
  year = {2003},
  journal = {Neural Networks},
  volume = {16},
  number = {5},
  pages = {763--770},
  issn = {0893-6080},
  doi = {10.1016/S0893-6080(03)00087-X},
  abstract = {Refined concepts, such as Rademacher estimates of model complexity and nonlinear criteria for weighting empirical classification errors, represent recent and promising approaches to characterize the generalization ability of Support Vector Machines (SVMs). The advantages of those techniques lie in both improving the SVM representation ability and yielding tighter generalization bounds. On the other hand, they often make Quadratic-Programming algorithms no longer applicable, and SVM training cannot benefit from efficient, specialized optimization techniques. The paper considers the application of Quantum Computing to solve the problem of effective SVM training, especially in the case of digital implementations. The presented research compares the behavioral aspects of conventional and enhanced SVMs; experiments in both a synthetic and real-world problems support the theoretical analysis. At the same time, the related differences between Quadratic-Programming and Quantum-based optimization techniques are considered.},
  keywords = {Quadratic-programming,Quantum optimization,Robust classification,Support vector machine},
  note = {Advances in Neural Networks Research: IJCNN '03}
}

@inproceedings{antonenkoMultimodalEnsemblesRegressor2022,
  title = {Multi-Modal {{Ensembles}} of~{{Regressor Chains}} for~{{Multi-output Prediction}}},
  booktitle = {Advances in {{Intelligent Data Analysis XX}}},
  author = {Antonenko, Ekaterina and Read, Jesse},
  editor = {Bouadi, Tassadit and Fromont, Elisa and H{\"u}llermeier, Eyke},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {1--13},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-031-01333-1_1},
  abstract = {Multi-target regression is a predictive task involving multiple numerical outputs per instance. In the domain of multi-label classification there exist a large number of techniques that successfully model outputs together. Classifier Chains is one such example that is naturally extendable to the multi-target regression task (as Regressor Chains). However, although this method is straightforward to adapt to the regression setting, large improvements over independent models (as seen already in the multi-label classification context over the recent decade) have not as of yet been obtained from Regressor Chains. One of the reasons for this is the adoption of squared-error-based loss metrics which do not require consideration of joint-target modeling. In this paper, we consider cases where the predictive distribution can be multi-modal. Such a scenario, which easily manifests in real-world tasks involving uncertainty, motivates a different loss metric and, thereby, a different approach. We thus present a new method for multi-target regression: Multi-Modal Ensemble of Regressor Chains (mmERC), which performs competitively on datasets exhibiting a multi-modal distribution, both against independent regressors and state-of-the-art ensembles of regressor chains. We argue that such distributions are not sufficiently considered in the regression and particularly multi-target regression literature.},
  isbn = {978-3-031-01333-1},
  langid = {english},
  keywords = {Multi-modal prediction,Multi-target regression,Regressor chains},
  file = {/Users/simon/Zotero/storage/7SJJ6PNE/Antonenko and Read - 2022 - Multi-modal Ensembles of Regressor Chains for Mult.pdf}
}

@inproceedings{arcainiModelingAnalyzingMAPEK2015,
  title = {Modeling and {{Analyzing MAPE-K Feedback Loops}} for {{Self-Adaptation}}},
  booktitle = {2015 {{IEEE}}/{{ACM}} 10th {{International Symposium}} on {{Software Engineering}} for {{Adaptive}} and {{Self-Managing Systems}}},
  author = {Arcaini, Paolo and Riccobene, Elvinia and Scandurra, Patrizia},
  year = {2015},
  month = may,
  pages = {13--23},
  issn = {2157-2321},
  doi = {10.1109/SEAMS.2015.10},
  abstract = {The MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) feedback loop is the most influential reference control model for autonomic and self-adaptive systems. This paper presents a conceptual and methodological framework for formal modeling, validating, and verifying distributed self-adaptive systems. We show how MAPE-K loops for self adaptation can be naturally specified in an abstract stateful language like Abstract State Machines. In particular, we exploit the concept of multi-agent Abstract State Machines to specify decentralized adaptation control by using MAPE computations. We support techniques for validating and verifying adaptation scenarios, and getting feedback of the correctness of the adaptation logic as implemented by the MAPE-K loops. In particular, a verification technique based on meta-properties is proposed to allow discovering unwanted interferences between MAPE-K loops at the early stages of the system design. As a proof-of concepts, we model and analyze a traffic monitoring system.},
  keywords = {Abstract State Machines,Adaptation models,Analytical models,Cameras,Computational modeling,formal modeling,MAPE-K,Monitoring,Organizations,self-adaptation,Unified modeling language,validation \& verification},
  file = {/Users/simon/Zotero/storage/2WFQW4VJ/7194653.html}
}

@misc{BackpropagationAppliedHandwritten,
  title = {Backpropagation {{Applied}} to {{Handwritten Zip Code Recognition}} | {{MIT Press Journals}} \& {{Magazine}} | {{IEEE Xplore}}},
  urldate = {2023-08-28},
  howpublished = {https://ieeexplore.ieee.org/document/6795724}
}

@article{baeza-delgadoPracticalSolutionEstimate2022,
  title = {A Practical Solution to Estimate the Sample Size Required for Clinical Prediction Models Generated from Observational Research on Data},
  author = {{Baeza-Delgado}, Carlos and Cerd{\'a} Alberich, Leonor and {Carot-Sierra}, Jos{\'e} Miguel and {Veiga-Canuto}, Diana and {Mart{\'i}nez de las Heras}, Blanca and Raza, Ben and {Mart{\'i}-Bonmat{\'i}}, Luis},
  year = {2022},
  month = jun,
  journal = {European Radiology Experimental},
  volume = {6},
  number = {1},
  pages = {22},
  issn = {2509-9280},
  doi = {10.1186/s41747-022-00276-y},
  urldate = {2023-04-22},
  abstract = {Estimating the required sample size is crucial when developing and validating clinical prediction models. However, there is no consensus about how to determine the sample size in such a setting. Here, the goal was to compare available methods to define a practical solution to sample size estimation for clinical predictive models, as applied to Horizon 2020 PRIMAGE as a case study.},
  keywords = {Clinical predictive models,Paediatric oncology,PRIMAGE,Radiology,Sample size calculation},
  file = {/Users/simon/Zotero/storage/JF6XNWI3/Baeza-Delgado et al. - 2022 - A practical solution to estimate the sample size r.pdf}
}

@misc{BERTPretrainingDeep,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}} | {{BibSonomy}}},
  urldate = {2023-06-10},
  howpublished = {https://www.bibsonomy.org/bibtex/210c860e3f390c6fbfd78a3b91ab9b0af/albinzehe},
  file = {/Users/simon/Zotero/storage/42G8WKCJ/albinzehe.html}
}

@misc{BetterWayFormat,
  title = {A Better Way to Format Your Document for {{CEUR-WS}}},
  urldate = {2023-06-01},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/project/646b7f680d0709347d53a6fd},
  langid = {english},
  file = {/Users/simon/Zotero/storage/G5FLYPP3/646b7f680d0709347d53a6fd.html}
}

@article{breimanRandomForests2001b,
  title = {Random {{Forests}}},
  author = {Breiman, Leo},
  year = {2001},
  month = oct,
  journal = {Machine Learning},
  volume = {45},
  number = {1},
  pages = {5--32},
  issn = {1573-0565},
  doi = {10.1023/A:1010933404324},
  urldate = {2023-06-10},
  abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\textendash 156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  langid = {english},
  keywords = {classification,ensemble,regression},
  file = {/Users/simon/Zotero/storage/S5CGZPMQ/Breiman - 2001 - Random Forests.pdf}
}

@article{cachedaArtificialIntelligenceSocial2018,
  title = {Artificial Intelligence and Social Networks for Early Detection of Depression ({{Preprint}})},
  author = {Cacheda, Fidel and Fern{\'a}ndez, Diego and N{\'o}voa, Francisco},
  year = {2018},
  month = oct,
  journal = {Journal of Medical Internet Research},
  volume = {21},
  doi = {10.2196/12554},
  file = {/Users/simon/Zotero/storage/7KQ8NA4E/Cacheda et al. - 2018 - Artificial intelligence and social networks for ea.pdf}
}

@misc{carionEndtoEndObjectDetection2020,
  title = {End-to-{{End Object Detection}} with {{Transformers}}},
  author = {Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  year = {2020},
  month = may,
  number = {arXiv:2005.12872},
  eprint = {2005.12872},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2005.12872},
  urldate = {2023-08-28},
  abstract = {We present a new method that views object detection as a direct set prediction problem. Our approach streamlines the detection pipeline, effectively removing the need for many hand-designed components like a non-maximum suppression procedure or anchor generation that explicitly encode our prior knowledge about the task. The main ingredients of the new framework, called DEtection TRansformer or DETR, are a set-based global loss that forces unique predictions via bipartite matching, and a transformer encoder-decoder architecture. Given a fixed small set of learned object queries, DETR reasons about the relations of the objects and the global image context to directly output the final set of predictions in parallel. The new model is conceptually simple and does not require a specialized library, unlike many other modern detectors. DETR demonstrates accuracy and run-time performance on par with the well-established and highly-optimized Faster RCNN baseline on the challenging COCO object detection dataset. Moreover, DETR can be easily generalized to produce panoptic segmentation in a unified manner. We show that it significantly outperforms competitive baselines. Training code and pretrained models are available at https://github.com/facebookresearch/detr.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/TVXMGPZG/Carion et al. - 2020 - End-to-End Object Detection with Transformers.pdf;/Users/simon/Zotero/storage/VDGFU4GC/2005.html}
}

@inproceedings{cayirFeatureExtractionBased2018,
  title = {Feature {{Extraction Based}} on {{Deep Learning}} for {{Some Traditional Machine Learning Methods}}},
  booktitle = {2018 3rd {{International Conference}} on {{Computer Science}} and {{Engineering}} ({{UBMK}})},
  author = {{\c C}ayir, Aykut and Yenido{\u g}an, I{\c s}il and Da{\u g}, Hasan},
  year = {2018},
  month = sep,
  pages = {494--497},
  doi = {10.1109/UBMK.2018.8566383},
  abstract = {Deep learning is a subfield of machine learning and deep neural architectures can extract high level features automatically without handcraft feature engineering unlike traditional machine learning algorithms. In this paper, we propose a method, which combines feature extraction layers of a convolutional neural network with traditional machine learning algorithms, such as, support vector machine, gradient boosting machines, and random forest. All of the proposed hybrid models and the above mentioned machine learning algorithms are trained on three different datasets: MNIST, Fashion-MNIST, and CIFAR-10. Results show that the proposed hybrid models are more successful than traditional models while they are being trained from raw pixel values. In this study, we empower traditional machine learning algorithms for classification using feature extraction ability of deep neural network architectures and we are inspired by transfer learning methodology to this.},
  keywords = {Convolutional neural networks,Data models,Feature extraction,Machine learning algorithms,Radio frequency,Support vector machines}
}

@misc{changRethinkingWhyIntermediateTask2021,
  title = {Rethinking {{Why Intermediate-Task Fine-Tuning Works}}},
  author = {Chang, Ting-Yun and Lu, Chi-Jen},
  year = {2021},
  month = sep,
  number = {arXiv:2108.11696},
  eprint = {2108.11696},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-05-31},
  abstract = {Supplementary Training on Intermediate Labeled-data Tasks (STILTs) is a widely applied technique, which first fine-tunes the pretrained language models on an intermediate task before on the target task of interest. While STILTs is able to further improve the performance of pretrained language models, it is still unclear why and when it works. Previous research shows that those intermediate tasks involving complex inference, such as commonsense reasoning, work especially well for RoBERTa. In this paper, we discover that the improvement from an intermediate task could be orthogonal to it containing reasoning or other complex skills -- a simple real-fake discrimination task synthesized by GPT2 can benefit diverse target tasks. We conduct extensive experiments to study the impact of different factors on STILTs. These findings suggest rethinking the role of intermediate fine-tuning in the STILTs pipeline.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  note = {Comment: Findings of EMNLP 2021},
  file = {/Users/simon/Zotero/storage/XRJE6GKY/Chang and Lu - 2021 - Rethinking Why Intermediate-Task Fine-Tuning Works.pdf;/Users/simon/Zotero/storage/JBPZ2Z7I/2108.html}
}

@misc{chenModSquadDesigningMixture2022,
  title = {Mod-{{Squad}}: {{Designing Mixture}} of {{Experts As Modular Multi-Task Learners}}},
  shorttitle = {Mod-{{Squad}}},
  author = {Chen, Zitian and Shen, Yikang and Ding, Mingyu and Chen, Zhenfang and Zhao, Hengshuang and {Learned-Miller}, Erik and Gan, Chuang},
  year = {2022},
  month = dec,
  number = {arXiv:2212.08066},
  eprint = {2212.08066},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-25},
  abstract = {Optimization in multi-task learning (MTL) is more challenging than single-task learning (STL), as the gradient from different tasks can be contradictory. When tasks are related, it can be beneficial to share some parameters among them (cooperation). However, some tasks require additional parameters with expertise in a specific type of data or discrimination (specialization). To address the MTL challenge, we propose Mod-Squad, a new model that is Modularized into groups of experts (a 'Squad'). This structure allows us to formalize cooperation and specialization as the process of matching experts and tasks. We optimize this matching process during the training of a single model. Specifically, we incorporate mixture of experts (MoE) layers into a transformer model, with a new loss that incorporates the mutual dependence between tasks and experts. As a result, only a small set of experts are activated for each task. This prevents the sharing of the entire backbone model between all tasks, which strengthens the model, especially when the training set size and the number of tasks scale up. More interestingly, for each task, we can extract the small set of experts as a standalone model that maintains the same performance as the large model. Extensive experiments on the Taskonomy dataset with 13 vision tasks and the PASCAL-Context dataset with 5 vision tasks show the superiority of our approach.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/simon/Zotero/storage/VV4R54R3/Chen et al. - 2022 - Mod-Squad Designing Mixture of Experts As Modular.pdf;/Users/simon/Zotero/storage/XYGFDPYZ/2212.html}
}

@article{chenStudyActiveLearning2015,
  title = {A Study of Active Learning Methods for Named Entity Recognition in Clinical Text},
  author = {Chen, Yukun and Lasko, Thomas A. and Mei, Qiaozhu and Denny, Joshua C. and Xu, Hua},
  year = {2015},
  month = dec,
  journal = {Journal of Biomedical Informatics},
  volume = {58},
  pages = {11--18},
  issn = {1532-0464},
  doi = {10.1016/j.jbi.2015.09.010},
  urldate = {2023-04-24},
  abstract = {Objectives Named entity recognition (NER), a sequential labeling task, is one of the fundamental tasks for building clinical natural language processing (NLP) systems. Machine learning (ML) based approaches can achieve good performance, but they often require large amounts of annotated samples, which are expensive to build due to the requirement of domain experts in annotation. Active learning (AL), a sample selection approach integrated with supervised ML, aims to minimize the annotation cost while maximizing the performance of ML-based models. In this study, our goal was to develop and evaluate both existing and new AL methods for a clinical NER task to identify concepts of medical problems, treatments, and lab tests from the clinical notes. Methods Using the annotated NER corpus from the 2010 i2b2/VA NLP challenge that contained 349 clinical documents with 20,423 unique sentences, we simulated AL experiments using a number of existing and novel algorithms in three different categories including uncertainty-based, diversity-based, and baseline sampling strategies. They were compared with the passive learning that uses random sampling. Learning curves that plot performance of the NER model against the estimated annotation cost (based on number of sentences or words in the training set) were generated to evaluate different active learning and the passive learning methods and the area under the learning curve (ALC) score was computed. Results Based on the learning curves of F-measure vs. number of sentences, uncertainty sampling algorithms outperformed all other methods in ALC. Most diversity-based methods also performed better than random sampling in ALC. To achieve an F-measure of 0.80, the best method based on uncertainty sampling could save 66\% annotations in sentences, as compared to random sampling. For the learning curves of F-measure vs. number of words, uncertainty sampling methods again outperformed all other methods in ALC. To achieve 0.80 in F-measure, in comparison to random sampling, the best uncertainty based method saved 42\% annotations in words. But the best diversity based method reduced only 7\% annotation effort. Conclusion In the simulated setting, AL methods, particularly uncertainty-sampling based approaches, seemed to significantly save annotation cost for the clinical NER task. The actual benefit of active learning in clinical NER should be further evaluated in a real-time setting.},
  langid = {english},
  keywords = {Active learning,Clinical named entity recognition,Clinical natural language processing,Machine learning},
  file = {/Users/simon/Zotero/storage/DMIB8XKJ/Chen et al. - 2015 - A study of active learning methods for named entit.pdf;/Users/simon/Zotero/storage/B4KRHVIZ/S1532046415002038.html}
}

@misc{cohenCertifiedAdversarialRobustness2019,
  title = {Certified {{Adversarial Robustness}} via {{Randomized Smoothing}}},
  author = {Cohen, Jeremy M. and Rosenfeld, Elan and Kolter, J. Zico},
  year = {2019},
  month = jun,
  number = {arXiv:1902.02918},
  eprint = {1902.02918},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1902.02918},
  urldate = {2023-05-16},
  abstract = {We show how to turn any classifier that classifies well under Gaussian noise into a new classifier that is certifiably robust to adversarial perturbations under the \$\textbackslash ell\_2\$ norm. This "randomized smoothing" technique has been proposed recently in the literature, but existing guarantees are loose. We prove a tight robustness guarantee in \$\textbackslash ell\_2\$ norm for smoothing with Gaussian noise. We use randomized smoothing to obtain an ImageNet classifier with e.g. a certified top-1 accuracy of 49\% under adversarial perturbations with \$\textbackslash ell\_2\$ norm less than 0.5 (=127/255). No certified defense has been shown feasible on ImageNet except for smoothing. On smaller-scale datasets where competing approaches to certified \$\textbackslash ell\_2\$ robustness are viable, smoothing delivers higher certified accuracies. Our strong empirical results suggest that randomized smoothing is a promising direction for future research into adversarially robust classification. Code and models are available at http://github.com/locuslab/smoothing.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: ICML 2019},
  file = {/Users/simon/Zotero/storage/ZQKGASSI/Cohen et al. - 2019 - Certified Adversarial Robustness via Randomized Sm.pdf;/Users/simon/Zotero/storage/MLGDMIRR/1902.html}
}

@inproceedings{dargahinobariAnalysisTelegramInstant2017,
  title = {Analysis of {{Telegram}}, {{An Instant Messaging Service}}},
  booktitle = {Proceedings of the 2017 {{ACM}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Dargahi Nobari, Arash and Reshadatmand, Negar and Neshati, Mahmood},
  year = {2017},
  month = nov,
  series = {{{CIKM}} '17},
  pages = {2035--2038},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3132847.3133132},
  urldate = {2023-06-02},
  abstract = {Telegram has become one of the most successful instant messaging services in recent years. In this paper, we developed a crawler to gather its public data. To the best of our knowledge, this paper is the first attempt to analyze the structural and topical aspects of messages published in Telegram instant messaging service using crawled data. We also extracted the mention graph and page rank of our data collection which indicates important differences between linking patterns of Telegram nodes and other usual networks. We also classified messages to detect advertisement and spam messages.},
  isbn = {978-1-4503-4918-5},
  keywords = {classification,instant messaging,pagerank,spam detection,telegram},
  file = {/Users/simon/Zotero/storage/FSYFJTPY/Dargahi Nobari et al. - 2017 - Analysis of Telegram, An Instant Messaging Service.pdf}
}

@misc{DeepLearningChest,
  title = {Deep {{Learning}} at {{Chest Radiography}}: {{Automated Classification}} of {{Pulmonary Tuberculosis}} by {{Using Convolutional Neural Networks}} | {{Radiology}}},
  urldate = {2023-08-25},
  howpublished = {https://pubs.rsna.org/doi/abs/10.1148/radiol.2017162326?journalCode=radiology},
  file = {/Users/simon/Zotero/storage/CY8G2JXY/radiol.html}
}

@inproceedings{dengImageNetLargescaleHierarchical2009,
  title = {{{ImageNet}}: {{A}} Large-Scale Hierarchical Image Database},
  shorttitle = {{{ImageNet}}},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and {Fei-Fei}, Li},
  year = {2009},
  month = jun,
  pages = {248--255},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2009.5206848},
  abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ``ImageNet'', a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500\textendash 1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  keywords = {Explosions,Image databases,Image retrieval,Information retrieval,Internet,Large-scale systems,Multimedia databases,Ontologies,Robustness,Spine}
}

@misc{DesigningMachineLearning,
  title = {Designing {{Machine Learning Systems}} [{{Book}}]},
  urldate = {2023-04-24},
  abstract = {Machine learning systems are both complex and unique. Complex because they consist of many different components and involve many different stakeholders. Unique because they're data dependent, with data varying wildly \ldots{} - Selection from Designing Machine Learning Systems [Book]},
  howpublished = {https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/},
  isbn = {9781098107963},
  langid = {english},
  file = {/Users/simon/Zotero/storage/EC9HG9WI/9781098107956.html}
}

@misc{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.04805},
  urldate = {2023-06-10},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simon/Zotero/storage/MKEUWG8B/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf;/Users/simon/Zotero/storage/YVEWRIZU/1810.html}
}

@misc{DiscussionSynonimGoogle,
  title = {Discussion Synonim - {{Google Search}}},
  urldate = {2023-08-30},
  howpublished = {https://www.google.com/search?q=discussion+synonim\&rlz=1C5CHFA\_enES997ES997\&oq=discussion+synonim\&gs\_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQABgKGIAEMgkIAhAAGAoYgAQyCQgDEAAYChiABDIJCAQQABgKGIAEMgkIBRAAGAoYgAQyCQgGEAAYChiABDIJCAcQABgKGIAEMgoICBAAGA8YFhgeMgoICRAAGAoYFhge0gEIMjA3MmowajeoAgCwAgA\&sourceid=chrome\&ie=UTF-8}
}

@misc{dohareLossPlasticityDeep2023,
  title = {Loss of {{Plasticity}} in {{Deep Continual Learning}}},
  author = {Dohare, Shibhansh and {Hernandez-Garcia}, J. Fernando and Rahman, Parash and Sutton, Richard S. and Mahmood, A. Rupam},
  year = {2023},
  month = aug,
  number = {arXiv:2306.13812},
  eprint = {2306.13812},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-08-30},
  abstract = {Modern deep-learning systems are specialized to problem settings in which training occurs once and then never again, as opposed to continual-learning settings in which training occurs continually. If deep-learning systems are applied in a continual learning setting, then it is well known that they may fail to remember earlier examples. More fundamental, but less well known, is that they may also lose their ability to learn on new examples, a phenomenon called loss of plasticity. We provide direct demonstrations of loss of plasticity using the MNIST and ImageNet datasets repurposed for continual learning as sequences of tasks. In ImageNet, binary classification performance dropped from 89\textbackslash\% accuracy on an early task down to 77\textbackslash\%, about the level of a linear network, on the 2000th task. Loss of plasticity occurred with a wide range of deep network architectures, optimizers, activation functions, batch normalization, dropout, but was substantially eased by \$L\^2\$-regularization, particularly when combined with weight perturbation. Further, we introduce a new algorithm -- continual backpropagation -- which slightly modifies conventional backpropagation to reinitialize a small fraction of less-used units after each example and appears to maintain plasticity indefinitely.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/simon/Zotero/storage/HPNPKUDV/Dohare et al. - 2023 - Loss of Plasticity in Deep Continual Learning.pdf;/Users/simon/Zotero/storage/2JRNCHZ9/2306.html}
}

@misc{dongRAFTRewardRAnked2023,
  title = {{{RAFT}}: {{Reward rAnked FineTuning}} for {{Generative Foundation Model Alignment}}},
  shorttitle = {{{RAFT}}},
  author = {Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong},
  year = {2023},
  month = apr,
  number = {arXiv:2304.06767},
  eprint = {2304.06767},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.06767},
  urldate = {2023-04-23},
  abstract = {Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generative models more effectively. Utilizing a reward model and a sufficient number of samples, our approach selects the high-quality samples, discarding those that exhibit undesired behavior, and subsequently assembles a streaming dataset. This dataset serves as the basis for aligning the generative model and can be employed under both offline and online settings. Notably, the sample generation process within RAFT is gradient-free, rendering it compatible with black-box generators. Through extensive experiments, we demonstrate that our proposed algorithm exhibits strong performance in the context of both large language models and diffusion models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/IIZEHKTZ/Dong et al. - 2023 - RAFT Reward rAnked FineTuning for Generative Foun.pdf;/Users/simon/Zotero/storage/YKGW34BD/2304.html}
}

@misc{ElementsStatisticalLearning,
  title = {Elements of {{Statistical Learning}}: Data Mining, Inference, and Prediction. 2nd {{Edition}}.},
  urldate = {2023-08-25},
  howpublished = {https://hastie.su.domains/ElemStatLearn/},
  file = {/Users/simon/Zotero/storage/P2WPTB85/ElemStatLearn.html}
}

@misc{ElementsStatisticalLearninga,
  title = {Elements of {{Statistical Learning}}: Data Mining, Inference, and Prediction. 2nd {{Edition}}.},
  urldate = {2023-08-25},
  howpublished = {https://hastie.su.domains/ElemStatLearn/}
}

@misc{ElementsStatisticalLearningb,
  title = {The {{Elements}} of {{Statistical Learning}}: {{Data Mining}}, {{Inference}}, and {{Prediction}}, {{Second Edition}} | {{SpringerLink}}},
  urldate = {2023-08-25},
  howpublished = {https://link.springer.com/book/10.1007/978-0-387-84858-7}
}

@article{estevaDeepLearningenabledMedical2021,
  title = {Deep Learning-Enabled Medical Computer Vision},
  author = {Esteva, Andre and Chou, Katherine and Yeung, Serena and Naik, Nikhil and Madani, Ali and Mottaghi, Ali and Liu, Yun and Topol, Eric and Dean, Jeff and Socher, Richard},
  year = {2021},
  month = jan,
  journal = {NPJ Digital Medicine},
  volume = {4},
  pages = {5},
  issn = {2398-6352},
  doi = {10.1038/s41746-020-00376-2},
  urldate = {2023-08-25},
  abstract = {A decade of unprecedented progress in artificial intelligence (AI) has demonstrated the potential for many fields\textemdash including medicine\textemdash to benefit from the insights that AI techniques can extract from data. Here we survey recent progress in the development of modern computer vision techniques\textemdash powered by deep learning\textemdash for medical applications, focusing on medical imaging, medical video, and clinical deployment. We start by briefly summarizing a decade of progress in convolutional neural networks, including the vision tasks they enable, in the context of healthcare. Next, we discuss several example medical imaging applications that stand to benefit\textemdash including cardiology, pathology, dermatology, ophthalmology\textendash and propose new avenues for continued work. We then expand into general medical video, highlighting ways in which clinical workflows can integrate computer vision to enhance care. Finally, we discuss the challenges and hurdles required for real-world clinical deployment of these technologies.},
  pmcid = {PMC7794558},
  pmid = {33420381},
  file = {/Users/simon/Zotero/storage/YPPAZNGC/Esteva et al. - 2021 - Deep learning-enabled medical computer vision.pdf}
}

@misc{EthicsGuidelinesTrustworthy2019,
  title = {Ethics Guidelines for Trustworthy {{AI}} | {{Shaping Europe}}'s Digital Future},
  year = {2019},
  month = apr,
  urldate = {2023-08-23},
  abstract = {On 8 April 2019, the High-Level Expert Group on AI presented Ethics Guidelines for Trustworthy Artificial Intelligence. This followed the publication of the guidelines' first draft in December 2018 on which more than 500 comments were received through an open consultation.},
  howpublished = {https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai},
  langid = {english},
  file = {/Users/simon/Zotero/storage/XCP85K2M/ethics-guidelines-trustworthy-ai.html}
}

@misc{EUAIAct2023,
  title = {{{EU AI Act}}: First Regulation on Artificial Intelligence | {{News}} | {{European Parliament}}},
  shorttitle = {{{EU AI Act}}},
  year = {2023},
  month = aug,
  urldate = {2023-08-23},
  abstract = {The use of artificial intelligence in the EU will be regulated by the AI Act, the world's first comprehensive AI law. Find out how it will protect you.},
  howpublished = {https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence},
  langid = {english},
  file = {/Users/simon/Zotero/storage/MSN4WILI/eu-ai-act-first-regulation-on-artificial-intelligence.html}
}

@misc{EuropeanAcceleratorTuberculosis,
  title = {European {{Accelerator}} of {{Tuberculosis Regime Project}}},
  journal = {ERA4TB},
  urldate = {2023-04-24},
  abstract = {A public-private initiative devoted to accelerate the development of new treatment regimens for tuberculosis. Part of IMI AMR accelerator.},
  howpublished = {https://era4tb.org/},
  langid = {american},
  file = {/Users/simon/Zotero/storage/CG2I2LAV/era4tb.org.html}
}

@article{everinghamPascalVisualObject2010,
  title = {The {{Pascal Visual Object Classes}} ({{VOC}}) {{Challenge}}},
  author = {Everingham, Mark and Gool, Luc and Williams, Christopher K. and Winn, John and Zisserman, Andrew},
  year = {2010},
  month = jun,
  journal = {International Journal of Computer Vision},
  volume = {88},
  number = {2},
  pages = {303--338},
  issn = {0920-5691},
  doi = {10.1007/s11263-009-0275-4},
  urldate = {2023-08-28},
  abstract = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
  keywords = {Benchmark,Database,Object detection,Object recognition},
  file = {/Users/simon/Zotero/storage/DJCU6KFR/Everingham et al. - 2010 - The Pascal Visual Object Classes (VOC) Challenge.pdf}
}

@misc{FAIRPrinciples,
  title = {{{FAIR Principles}}},
  journal = {GO FAIR},
  urldate = {2023-01-31},
  abstract = {In 2016, the `FAIR Guiding Principles for scientific data management and stewardship'~were published in~Scientific Data. The authors intended to provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets. The principles emphasise machine-actionability (i.e., the capacity of\ldots{} Continue reading \textrightarrow},
  howpublished = {https://www.go-fair.org/fair-principles/},
  langid = {american},
  file = {/Users/simon/Zotero/storage/EV9LR3JE/fair-principles.html}
}

@article{ferreiraEarlyRiskDetectiona,
  title = {Early Risk Detection of Mental Illnesses Using Various Types of Textual Features},
  author = {Ferreira, Rodrigo and Trifan, Alina and Oliveira, Jos{\'e} Lu{\'i}s},
  abstract = {This paper documents the participation of our team, BioInfo@UAVR, in the first and second task of the 2022 edition of CLEF eRisk. With the goal of achieving an early detection of subjects at risk of specific mental illnesses, pathological gambling and depression for tasks 1 and 2 respectively, using data sourced from social networks, more specifically, Reddit. To this end, we trained several machine learning models, dividing our experiments into three feature engineering approaches of increasing complexity, corresponding to very commonly used vectorization methods in natural language processing, those of bag-of-words, distributional semantics word embeddings and contextualized language models. Additionally, we evaluated the impact of the inclusion of sentiment analysis features. Despite having subpar results on the official evaluation, we managed to improve them considerably post submission with a few tweaks, showing that these solutions can work if properly fine-tuned.},
  langid = {english},
  file = {/Users/simon/Zotero/storage/KFR8772B/Ferreira et al. - Early risk detection of mental illnesses using var.pdf}
}

@article{figueroaPredictingSampleSize2012,
  title = {Predicting Sample Size Required for Classification Performance},
  author = {Figueroa, Rosa L. and {Zeng-Treitler}, Qing and Kandula, Sasikiran and Ngo, Long H.},
  year = {2012},
  month = feb,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {12},
  number = {1},
  pages = {8},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-12-8},
  urldate = {2023-04-24},
  abstract = {Supervised learning methods need annotated data in order to generate efficient models. Annotated data, however, is a relatively scarce resource and can be expensive to obtain. For both passive and active learning methods, there is a need to estimate the size of the annotated sample required to reach a performance target.},
  keywords = {Active Learning,Annotate Data,Learning Curve,Mean Absolute Error,Root Mean Square Error},
  file = {/Users/simon/Zotero/storage/J5IICHCW/Figueroa et al. - 2012 - Predicting sample size required for classification.pdf;/Users/simon/Zotero/storage/YCXXRYM5/1472-6947-12-8.html}
}

@article{friedmanGreedyFunctionApproximation2000,
  title = {Greedy {{Function Approximation}}: {{A Gradient Boosting Machine}}},
  shorttitle = {Greedy {{Function Approximation}}},
  author = {Friedman, Jerome},
  year = {2000},
  month = nov,
  journal = {The Annals of Statistics},
  volume = {29},
  doi = {10.1214/aos/1013203451},
  abstract = {Function approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest--descent minimization. A general gradient--descent "boosting" paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least--squares, least--absolute--deviation, and Huber--M loss functions for regression, and multi--class logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are decision trees, and tools for interpreting such "TreeBoost" models are presented. Gradient boosting of decision trees produces competitive, highly robust, interpretable procedures for regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire 1996, and Fr...},
  file = {/Users/simon/Zotero/storage/L5XZRTZT/Friedman - 2000 - Greedy Function Approximation A Gradient Boosting.pdf}
}

@article{gheibiApplyingMachineLearning2021,
  title = {Applying {{Machine Learning}} in {{Self-adaptive Systems}}: {{A Systematic Literature Review}}},
  shorttitle = {Applying {{Machine Learning}} in {{Self-adaptive Systems}}},
  author = {Gheibi, Omid and Weyns, Danny and Quin, Federico},
  year = {2021},
  month = aug,
  journal = {ACM Transactions on Autonomous and Adaptive Systems},
  volume = {15},
  number = {3},
  pages = {9:1--9:37},
  issn = {1556-4665},
  doi = {10.1145/3469440},
  urldate = {2023-08-27},
  abstract = {Recently, we have been witnessing a rapid increase in the use of machine learning techniques in self-adaptive systems. Machine learning has been used for a variety of reasons, ranging from learning a model of the environment of a system during operation to filtering large sets of possible configurations before analyzing them. While a body of work on the use of machine learning in self-adaptive systems exists, there is currently no systematic overview of this area. Such an overview is important for researchers to understand the state of the art and direct future research efforts. This article reports the results of a systematic literature review that aims at providing such an overview. We focus on self-adaptive systems that are based on a traditional Monitor-Analyze-Plan-Execute (MAPE)-based feedback loop. The research questions are centered on the problems that motivate the use of machine learning in self-adaptive systems, the key engineering aspects of learning in self-adaptation, and open challenges in this area. The search resulted in 6,709 papers, of which 109 were retained for data collection. Analysis of the collected data shows that machine learning is mostly used for updating adaptation rules and policies to improve system qualities, and managing resources to better balance qualities and resources. These problems are primarily solved using supervised and interactive learning with classification, regression, and reinforcement learning as the dominant methods. Surprisingly, unsupervised learning that naturally fits automation is only applied in a small number of studies. Key open challenges in this area include the performance of learning, managing the effects of learning, and dealing with more complex types of goals. From the insights derived from this systematic literature review, we outline an initial design process for applying machine learning in self-adaptive systems that are based on MAPE feedback loops.},
  keywords = {feedback loops,MAPE-K,Self-adaptation},
  file = {/Users/simon/Zotero/storage/5A7QKC9C/Gheibi et al. - 2021 - Applying Machine Learning in Self-adaptive Systems.pdf}
}

@misc{girshickFastRCNN2015,
  title = {Fast {{R-CNN}}},
  author = {Girshick, Ross},
  year = {2015},
  month = sep,
  number = {arXiv:1504.08083},
  eprint = {1504.08083},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1504.08083},
  urldate = {2023-08-28},
  abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: To appear in ICCV 2015},
  file = {/Users/simon/Zotero/storage/IRUJHIFF/Girshick - 2015 - Fast R-CNN.pdf;/Users/simon/Zotero/storage/ACKREE5Q/1504.html}
}

@misc{girshickRichFeatureHierarchies2014,
  title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
  author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  year = {2014},
  month = oct,
  number = {arXiv:1311.2524},
  eprint = {1311.2524},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1311.2524},
  urldate = {2023-08-28},
  abstract = {Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30\% relative to the previous best result on VOC 2012---achieving a mAP of 53.3\%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also compare R-CNN to OverFeat, a recently proposed sliding-window detector based on a similar CNN architecture. We find that R-CNN outperforms OverFeat by a large margin on the 200-class ILSVRC2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/\textasciitilde rbg/rcnn.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: Extended version of our CVPR 2014 paper; latest update (v5) includes results using deeper networks (see Appendix G. Changelog)},
  file = {/Users/simon/Zotero/storage/TCVTV86Z/Girshick et al. - 2014 - Rich feature hierarchies for accurate object detec.pdf;/Users/simon/Zotero/storage/LGZNJBXR/1311.html}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {{MIT press}}
}

@misc{goodfellowExplainingHarnessingAdversarial2015,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  year = {2015},
  month = mar,
  number = {arXiv:1412.6572},
  eprint = {1412.6572},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6572},
  urldate = {2023-05-16},
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/7MPJDPDC/Goodfellow et al. - 2015 - Explaining and Harnessing Adversarial Examples.pdf;/Users/simon/Zotero/storage/XBKAFX5Q/1412.html}
}

@misc{goodfellowExplainingHarnessingAdversarial2015a,
  title = {Explaining and {{Harnessing Adversarial Examples}}},
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  year = {2015},
  month = mar,
  number = {arXiv:1412.6572},
  eprint = {1412.6572},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-08-27},
  abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/TVYL35PN/Goodfellow et al. - 2015 - Explaining and Harnessing Adversarial Examples.pdf;/Users/simon/Zotero/storage/TBECUVL2/1412.html}
}

@article{gulamaliAutoencodersSampleSize2022a,
  title = {Autoencoders for Sample Size Estimation for Fully Connected Neural Network Classifiers},
  author = {Gulamali, Faris F. and Sawant, Ashwin S. and Kovatch, Patricia and Glicksberg, Benjamin and Charney, Alexander and Nadkarni, Girish N. and Oermann, Eric},
  year = {2022},
  month = dec,
  journal = {npj Digital Medicine},
  volume = {5},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00728-0},
  urldate = {2023-04-22},
  abstract = {Sample size estimation is a crucial step in experimental design but is understudied in the context of deep learning. Currently, estimating the quantity of labeled data needed to train a classifier to a desired performance, is largely based on prior experience with similar models and problems or on untested heuristics. In many supervised machine learning applications, data labeling can be expensive and time-consuming and would benefit from a more rigorous means of estimating labeling requirements. Here, we study the problem of estimating the minimum sample size of labeled training data necessary for training computer vision models as an exemplar for other deep learning problems. We consider the problem of identifying the minimal number of labeled data points to achieve a generalizable representation of the data, a minimum converging sample (MCS). We use autoencoder loss to estimate the MCS for fully connected neural network classifiers. At sample sizes smaller than the MCS estimate, fully connected networks fail to distinguish classes, and at sample sizes above the MCS estimate, generalizability strongly correlates with the loss function of the autoencoder. We provide an easily accessible, code-free, and dataset-agnostic tool to estimate sample sizes for fully connected networks. Taken together, our findings suggest that MCS and convergence estimation are promising methods to guide sample size estimates for data collection and labeling prior to training deep learning models in computer vision.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Epidemiology,Statistics},
  file = {/Users/simon/Zotero/storage/A9VAC3ZH/Gulamali et al. - 2022 - Autoencoders for sample size estimation for fully .pdf}
}

@misc{Hackathonsomosnlp2023RobertabasebnefinetunedsuicideesHugging2023,
  title = {Hackathon-Somos-Nlp-2023/Roberta-Base-Bne-Finetuned-Suicide-Es {$\cdot$} {{Hugging Face}}},
  year = {2023},
  month = apr,
  urldate = {2023-05-31},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/hackathon-somos-nlp-2023/roberta-base-bne-finetuned-suicide-es},
  file = {/Users/simon/Zotero/storage/GKA8DD2N/roberta-base-bne-finetuned-suicide-es.html}
}

@article{haoTechnologyOrientedPathwayAuxiliary2022,
  title = {The {{Technology-Oriented Pathway}} for {{Auxiliary Diagnosis}} in the {{Digital Health Age}}: {{A Self-Adaptive Disease Prediction Model}}},
  shorttitle = {The {{Technology-Oriented Pathway}} for {{Auxiliary Diagnosis}} in the {{Digital Health Age}}},
  author = {Hao, Zhiyuan and Ma, Jie and Sun, Wenjing},
  year = {2022},
  month = sep,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {19},
  number = {19},
  pages = {12509},
  issn = {1661-7827},
  doi = {10.3390/ijerph191912509},
  urldate = {2023-08-30},
  abstract = {The advent of the digital age has accelerated the transformation and upgrading of the traditional medical diagnosis pattern. With the rise of the concept of digital health, the emerging information technologies, such as machine learning (ML) and data mining (DM), have been extensively applied in the medical and health field, where the construction of disease prediction models is an especially effective method to realize auxiliary medical diagnosis. However, the existing related studies mostly focus on the prediction analysis for a certain disease, using models with which it might be challenging to predict other diseases effectively. To address the issues existing in the aforementioned studies, this paper constructs four novel strategies to achieve a self-adaptive disease prediction process, i.e., the hunger-state foraging strategy of producers (PHFS), the parallel strategy for exploration and exploitation (EEPS), the perturbation\textendash exploration strategy (PES), and the parameter self-adaptive strategy (PSAS), and eventually proposes a self-adaptive disease prediction model with applied universality, strong generalization ability, and strong robustness, i.e., multi-strategies optimization-based kernel extreme learning machine (MsO-KELM). Meanwhile, this paper selects six different real-world disease datasets as the experimental samples, which include the Breast Cancer dataset (cancer), the Parkinson dataset (Parkinson's disease), the Autistic Spectrum Disorder Screening Data for Children dataset (Autism Spectrum Disorder), the Heart Disease dataset (heart disease), the Cleveland dataset (heart disease), and the Bupa dataset (liver disease). In terms of the prediction accuracy, the proposed MsO-KELM can obtain ACC values in analyzing these six diseases of 94.124\%, 84.167\%, 91.079\%, 72.222\%, 70.184\%, and 70.476\%, respectively. These ACC values have all been increased by nearly 2\textendash 7\% compared with those obtained by the other models mentioned in this paper. This study deepens the connection between information technology and medical health by exploring the self-adaptive disease prediction model, which is an intuitive representation of digital health and could provide a scientific and reliable diagnostic basis for medical workers.},
  pmcid = {PMC9566816},
  pmid = {36231805}
}

@article{healthArtificialIntelligenceMachine2022,
  title = {Artificial {{Intelligence}} and {{Machine Learning}} ({{AI}}/{{ML}})-{{Enabled Medical Devices}}},
  author = {Health, Center for Devices {and} Radiological},
  year = {Wed, 10/05/2022 - 11:34},
  journal = {FDA},
  publisher = {{FDA}},
  urldate = {2023-08-26},
  abstract = {The FDA has updated the list of AI/ML-enabled medical devices marketed in the United States as a resource to the public.},
  langid = {english},
  file = {/Users/simon/Zotero/storage/RIHPVRGA/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices.html}
}

@incollection{heSpatialPyramidPooling2014,
  title = {Spatial {{Pyramid Pooling}} in {{Deep Convolutional Networks}} for {{Visual Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2014},
  volume = {8691},
  eprint = {1406.4729},
  primaryclass = {cs},
  pages = {346--361},
  doi = {10.1007/978-3-319-10578-9_23},
  urldate = {2023-08-28},
  abstract = {Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. This requirement is "artificial" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, "spatial pyramid pooling", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102x faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank \#2 in object detection and \#3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: This manuscript is the accepted version for IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2015. See Changelog},
  file = {/Users/simon/Zotero/storage/XSQRR9DB/He et al. - 2014 - Spatial Pyramid Pooling in Deep Convolutional Netw.pdf;/Users/simon/Zotero/storage/LCKAAFCH/1406.html}
}

@article{hoerlRidgeRegressionBiased1970,
  title = {Ridge {{Regression}}: {{Biased Estimation}} for {{Nonorthogonal Problems}}},
  shorttitle = {Ridge {{Regression}}},
  author = {Hoerl, Arthur E. and Kennard, Robert W.},
  year = {1970},
  journal = {Technometrics},
  volume = {12},
  number = {1},
  eprint = {1267351},
  eprinttype = {jstor},
  pages = {55--67},
  publisher = {{[Taylor \& Francis, Ltd., American Statistical Association, American Society for Quality]}},
  issn = {0040-1706},
  doi = {10.2307/1267351},
  urldate = {2023-06-10},
  abstract = {In multiple regression it is shown that parameter estimates based on minimum residual sum of squares have a high probability of being unsatisfactory, if not incorrect, if the prediction vectors are not orthogonal. Proposed is an estimation procedure based on adding small positive quantities to the diagonal of X{${'}$}X. Introduced is the ridge trace, a method for showing in two dimensions the effects of nonorthogonality. It is then shown how to augment X{${'}$}X to obtain biased estimates with smaller mean square error.}
}

@misc{holzmullerFrameworkBenchmarkDeep2023,
  title = {A {{Framework}} and {{Benchmark}} for {{Deep Batch Active Learning}} for {{Regression}}},
  author = {Holzm{\"u}ller, David and Zaverkin, Viktor and K{\"a}stner, Johannes and Steinwart, Ingo},
  year = {2023},
  month = aug,
  number = {arXiv:2203.09410},
  eprint = {2203.09410},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2203.09410},
  urldate = {2023-08-23},
  abstract = {The acquisition of labels for supervised learning can be expensive. To improve the sample efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations, and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width neural tangent kernels and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or training code. We provide open-source code that includes efficient implementations of all kernels, kernel transformations, and selection methods, and can be used for reproducing our results.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  note = {Comment: Published at the Journal of Machine Learning Research (JMLR). Changes in v4: Improvements in writing and other minor changes. Accompanying code can be found at https://github.com/dholzmueller/bmdal\_reg},
  file = {/Users/simon/Zotero/storage/XZ87PMZ5/Holzmüller et al. - 2023 - A Framework and Benchmark for Deep Batch Active Le.pdf;/Users/simon/Zotero/storage/27SAK989/2203.html}
}

@misc{hwangTutelAdaptiveMixtureofExperts2023,
  title = {Tutel: {{Adaptive Mixture-of-Experts}} at {{Scale}}},
  shorttitle = {Tutel},
  author = {Hwang, Changho and Cui, Wei and Xiong, Yifan and Yang, Ziyue and Liu, Ze and Hu, Han and Wang, Zilong and Salas, Rafael and Jose, Jithin and Ram, Prabhat and Chau, Joe and Cheng, Peng and Yang, Fan and Yang, Mao and Xiong, Yongqiang},
  year = {2023},
  month = jun,
  number = {arXiv:2206.03382},
  eprint = {2206.03382},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-14},
  abstract = {Sparsely-gated mixture-of-experts (MoE) has been widely adopted to scale deep learning models to trillion-plus parameters with fixed computational cost. The algorithmic performance of MoE relies on its token routing mechanism that forwards each input token to the right sub-models or experts. While token routing dynamically determines the amount of expert workload at runtime, existing systems suffer inefficient computation due to their static execution, namely static parallelism and pipelining, which does not adapt to the dynamic workload. We present Flex, a highly scalable stack design and implementation for MoE with dynamically adaptive parallelism and pipelining. Flex designs an identical layout for distributing MoE model parameters and input data, which can be leveraged by all possible parallelism or pipelining methods without any mathematical inequivalence or tensor migration overhead. This enables adaptive parallelism/pipelining optimization at zero cost during runtime. Based on this key design, Flex also implements various MoE acceleration techniques. Aggregating all techniques, Flex finally delivers huge speedup at any scale -- 4.96x and 5.75x speedup of a single MoE layer over 16 and 2,048 A100 GPUs, respectively, over the previous state-of-the-art. Our evaluation shows that Flex efficiently and effectively runs a real-world MoE-based model named SwinV2-MoE, built upon Swin Transformer V2, a state-of-the-art computer vision architecture. On efficiency, Flex accelerates SwinV2-MoE, achieving up to 1.55x and 2.11x speedup in training and inference over Fairseq, respectively. On effectiveness, the SwinV2-MoE model achieves superior accuracy in both pre-training and down-stream computer vision tasks such as COCO object detection than the counterpart dense model, indicating the readiness of Flex for end-to-end real-world model training and inference.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/Users/simon/Zotero/storage/7HHCF4FV/Hwang et al. - 2023 - Tutel Adaptive Mixture-of-Experts at Scale.pdf;/Users/simon/Zotero/storage/8LH2DBTW/2206.html}
}

@misc{ilyasPriorConvictionsBlackBox2019,
  title = {Prior {{Convictions}}: {{Black-Box Adversarial Attacks}} with {{Bandits}} and {{Priors}}},
  shorttitle = {Prior {{Convictions}}},
  author = {Ilyas, Andrew and Engstrom, Logan and Madry, Aleksander},
  year = {2019},
  month = mar,
  number = {arXiv:1807.07978},
  eprint = {1807.07978},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-16},
  abstract = {We study the problem of generating adversarial examples in a black-box setting in which only loss-oracle access to a model is available. We introduce a framework that conceptually unifies much of the existing work on black-box attacks, and we demonstrate that the current state-of-the-art methods are optimal in a natural sense. Despite this optimality, we show how to improve black-box attacks by bringing a new element into the problem: gradient priors. We give a bandit optimization-based algorithm that allows us to seamlessly integrate any such priors, and we explicitly identify and incorporate two examples. The resulting methods use two to four times fewer queries and fail two to five times less often than the current state-of-the-art.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: To appear at ICLR 2019; Code available at https://git.io/blackbox-bandits},
  file = {/Users/simon/Zotero/storage/VWHYMA8U/Ilyas et al. - 2019 - Prior Convictions Black-Box Adversarial Attacks w.pdf;/Users/simon/Zotero/storage/R3QBFW9L/1807.html}
}

@misc{jaderbergSpatialTransformerNetworks2016,
  title = {Spatial {{Transformer Networks}}},
  author = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
  year = {2016},
  month = feb,
  number = {arXiv:1506.02025},
  eprint = {1506.02025},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1506.02025},
  urldate = {2023-08-29},
  abstract = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner. In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/LAJVHQNC/Jaderberg et al. - 2016 - Spatial Transformer Networks.pdf;/Users/simon/Zotero/storage/PW6VW8EU/1506.html}
}

@article{jhaContinualLearningSensorbased2021,
  title = {Continual Learning in Sensor-Based Human Activity Recognition: {{An}} Empirical Benchmark Analysis},
  shorttitle = {Continual Learning in Sensor-Based Human Activity Recognition},
  author = {Jha, Saurav and Schiemer, Martin and Zambonelli, Franco and Ye, Juan},
  year = {2021},
  month = oct,
  journal = {Information Sciences},
  volume = {575},
  pages = {1--21},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2021.04.062},
  urldate = {2023-08-30},
  abstract = {Sensor-based human activity recognition (HAR), i.e., the ability to discover human daily activity patterns from wearable or embedded sensors, is a key enabler for many real-world applications in smart homes, personal healthcare, and urban planning. However, with an increasing number of applications being deployed, an important question arises: how can a HAR system autonomously learn new activities over a long period of time without being re-engineered from scratch? This problem is known as continual learning and has been particularly popular in the domain of computer vision, where several techniques to attack it have been developed. This paper aims to assess to what extent such continual learning techniques can be applied to the HAR domain. To this end, we propose a general framework to evaluate the performance of such techniques on various types of commonly used HAR datasets. Then, we present a comprehensive empirical analysis of their computational cost and of their effectiveness of tackling HAR specific challenges (i.e., sensor noise and labels' scarcity). The presented results uncover useful insights on their applicability and suggest future research directions for HAR systems.},
  keywords = {Continual learning,Human activity recognition,Incremental learning,Lifelong learning},
  file = {/Users/simon/Zotero/storage/5C3DTK4K/Jha et al. - 2021 - Continual learning in sensor-based human activity .pdf;/Users/simon/Zotero/storage/DX2BEZGZ/S0020025521003911.html}
}

@article{jinQuantifyingGeneralizationError2020,
  title = {Quantifying the Generalization Error in Deep Learning in Terms of Data Distribution and Neural Network Smoothness},
  author = {Jin, Pengzhan and Lu, Lu and Tang, Yifa and Karniadakis, George Em},
  year = {2020},
  month = oct,
  journal = {Neural Networks},
  volume = {130},
  pages = {85--99},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2020.06.024},
  urldate = {2023-04-22},
  abstract = {The accuracy of deep learning, i.e., deep neural networks, can be characterized by dividing the total error into three main types: approximation error, optimization error, and generalization error. Whereas there are some satisfactory answers to the problems of approximation and optimization, much less is known about the theory of generalization. Most existing theoretical works for generalization fail to explain the performance of neural networks in practice. To derive a meaningful bound, we study the generalization error of neural networks for classification problems in terms of data distribution and neural network smoothness. We introduce the cover complexity (CC) to measure the difficulty of learning a data set and the inverse of the modulus of continuity to quantify neural network smoothness. A quantitative bound for expected accuracy/error is derived by considering both the CC and neural network smoothness. Although most of the analysis is general and not specific to neural networks, we validate our theoretical assumptions and results numerically for neural networks by several data sets of images. The numerical results confirm that the expected error of trained networks scaled with the square root of the number of classes has a linear relationship with respect to the CC. We also observe a clear consistency between test loss and neural network smoothness during the training process. In addition, we demonstrate empirically that the neural network smoothness decreases when the network size increases whereas the smoothness is insensitive to training dataset size.},
  langid = {english},
  keywords = {Cover complexity,Data distribution,Generalization error,Learnability,Neural network smoothness,Neural networks},
  file = {/Users/simon/Zotero/storage/LF8HGD4J/Jin et al. - 2020 - Quantifying the generalization error in deep learn.pdf;/Users/simon/Zotero/storage/K567FP22/S0893608020302392.html}
}

@article{johnsonExtensionsLipschitzMaps1984,
  title = {Extensions of {{Lipschitz}} Maps into a {{Hilbert}} Space},
  author = {Johnson, William and Lindenstrauss, Joram},
  year = {1984},
  month = jan,
  journal = {Contemporary Mathematics},
  volume = {26},
  pages = {189--206},
  issn = {9780821850305},
  doi = {10.1090/conm/026/737400},
  file = {/Users/simon/Zotero/storage/I673GQBF/Johnson and Lindenstrauss - 1984 - Extensions of Lipschitz maps into a Hilbert space.pdf}
}

@article{jumperHighlyAccurateProtein2021,
  title = {Highly Accurate Protein Structure Prediction with {{AlphaFold}}},
  author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v Z}{\'i}dek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and {Romera-Paredes}, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
  year = {2021},
  month = aug,
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {583--589},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-03819-2},
  urldate = {2023-08-26},
  abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1\textendash 4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence\textemdash the structure prediction component of the `protein folding problem'8\textemdash has been an important open research problem for more than 50~years9. Despite recent progress10\textendash 14, existing methods fall far~short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Computational biophysics,Machine learning,Protein structure predictions,Structural biology},
  file = {/Users/simon/Zotero/storage/SU3UKJ5W/Jumper et al. - 2021 - Highly accurate protein structure prediction with .pdf}
}

@article{kakumaHumanResourcesMental2011,
  title = {Human Resources for Mental Health Care: Current Situation and Strategies for Action},
  shorttitle = {Human Resources for Mental Health Care},
  author = {Kakuma, Ritsuko and Minas, Harry and {van Ginneken}, Nadja and Dal Poz, Mario R and Desiraju, Keshav and Morris, Jodi E and Saxena, Shekhar and Scheffler, Richard M},
  year = {2011},
  month = nov,
  journal = {The Lancet},
  volume = {378},
  number = {9803},
  pages = {1654--1663},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(11)61093-3},
  urldate = {2023-05-29},
  abstract = {A challenge faced by many countries is to provide adequate human resources for delivery of essential mental health interventions. The overwhelming worldwide shortage of human resources for mental health, particularly in low-income and middle-income countries, is well established. Here, we review the current state of human resources for mental health, needs, and strategies for action. At present, human resources for mental health in countries of low and middle income show a serious shortfall that is likely to grow unless effective steps are taken. Evidence suggests that mental health care can be delivered effectively in primary health-care settings, through community-based programmes and task-shifting approaches. Non-specialist health professionals, lay workers, affected individuals, and caregivers with brief training and appropriate supervision by mental health specialists are able to detect, diagnose, treat, and monitor individuals with mental disorders and reduce caregiver burden. We also discuss scale-up costs, human resources management, and leadership for mental health, particularly within the context of low-income and middle-income countries.},
  langid = {english},
  file = {/Users/simon/Zotero/storage/9VYFJG6X/Kakuma et al. - 2011 - Human resources for mental health care current si.pdf;/Users/simon/Zotero/storage/KQQ6QSY8/S0140673611610933.html}
}

@article{kephartVisionAutonomicComputing2003,
  title = {The {{Vision Of Autonomic Computing}}},
  author = {Kephart, Jeffrey and Chess, D.M.},
  year = {2003},
  month = feb,
  journal = {Computer},
  volume = {36},
  pages = {41--50},
  doi = {10.1109/MC.2003.1160055},
  abstract = {A 2001 IBM manifesto observed that a looming software complexity crisis -caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.},
  file = {/Users/simon/Zotero/storage/HCQ9YAQM/Kephart and Chess - 2003 - The Vision Of Autonomic Computing.pdf}
}

@article{keutzerMachineLearningPharmacometrics2022,
  title = {Machine {{Learning}} and {{Pharmacometrics}} for {{Prediction}} of {{Pharmacokinetic Data}}: {{Differences}}, {{Similarities}} and {{Challenges Illustrated}} with {{Rifampicin}}},
  shorttitle = {Machine {{Learning}} and {{Pharmacometrics}} for {{Prediction}} of {{Pharmacokinetic Data}}},
  author = {Keutzer, Lina and You, Huifang and Farnoud, Ali and Nyberg, Joakim and Wicha, Sebastian G. and {Maher-Edwards}, Gareth and Vlasakakis, Georgios and Moghaddam, Gita Khalili and Svensson, Elin M. and Menden, Michael P. and Simonsson, Ulrika S. H. and On Behalf Of The Unite Tb Consortium, null},
  year = {2022},
  month = jul,
  journal = {Pharmaceutics},
  volume = {14},
  number = {8},
  pages = {1530},
  issn = {1999-4923},
  doi = {10.3390/pharmaceutics14081530},
  abstract = {Pharmacometrics (PM) and machine learning (ML) are both valuable for drug development to characterize pharmacokinetics (PK) and pharmacodynamics (PD). Pharmacokinetic/pharmacodynamic (PKPD) analysis using PM provides mechanistic insight into biological processes but is time- and labor-intensive. In contrast, ML models are much quicker trained, but offer less mechanistic insights. The opportunity of using ML predictions of drug PK as input for a PKPD model could strongly accelerate analysis efforts. Here exemplified by rifampicin, a widely used antibiotic, we explore the ability of different ML algorithms to predict drug PK. Based on simulated data, we trained linear regressions (LASSO), Gradient Boosting Machines, XGBoost and Random Forest to predict the plasma concentration-time series and rifampicin area under the concentration-versus-time curve from 0-24 h (AUC0-24h) after repeated dosing. XGBoost performed best for prediction of the entire PK series (R2: 0.84, root mean square error (RMSE): 6.9 mg/L, mean absolute error (MAE): 4.0 mg/L) for the scenario with the largest data size. For AUC0-24h prediction, LASSO showed the highest performance (R2: 0.97, RMSE: 29.1 h{$\cdot$}mg/L, MAE: 18.8 h{$\cdot$}mg/L). Increasing the number of plasma concentrations per patient (0, 2 or 6 concentrations per occasion) improved model performance. For example, for AUC0-24h prediction using LASSO, the R2 was 0.41, 0.69 and 0.97 when using predictors only (no plasma concentrations), 2 or 6 plasma concentrations per occasion as input, respectively. Run times for the ML models ranged from 1.0 s to 8 min, while the run time for the PM model was more than 3 h. Furthermore, building a PM model is more time- and labor-intensive compared with ML. ML predictions of drug PK could thus be used as input into a PKPD model, enabling time-efficient analysis.},
  langid = {english},
  pmcid = {PMC9330804},
  pmid = {35893785},
  keywords = {feature selection,machine learning,pharmacokinetics,pharmacometrics,population pharmacokinetics,rifampicin,simulation},
  file = {/Users/simon/Zotero/storage/2QA59H48/Keutzer et al. - 2022 - Machine Learning and Pharmacometrics for Predictio.pdf}
}

@article{khaliliaPredictingDiseaseRisks2011,
  title = {Predicting Disease Risks from Highly Imbalanced Data Using Random Forest},
  author = {Khalilia, Mohammed and Chakraborty, Sounak and Popescu, Mihail},
  year = {2011},
  month = jul,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {11},
  number = {1},
  pages = {51},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-11-51},
  urldate = {2023-04-25},
  abstract = {We present a method utilizing Healthcare Cost and Utilization Project (HCUP) dataset for predicting disease risk of individuals based on their medical diagnosis history. The presented methodology may be incorporated in a variety of applications such as risk management, tailored health communication and decision support systems in healthcare.},
  langid = {english},
  keywords = {Disease Prediction,Imbalanced Data,National Inpatient Sample,Random Forest,Support Vector Machine},
  file = {/Users/simon/Zotero/storage/UXRIBLA3/Khalilia et al. - 2011 - Predicting disease risks from highly imbalanced da.pdf}
}

@inproceedings{khanKnowledgeAdaptationPriors2021,
  title = {Knowledge-{{Adaptation Priors}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Khan, Mohammad Emtiyaz E and Swaroop, Siddharth},
  year = {2021},
  volume = {34},
  pages = {19757--19770},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-07-14},
  abstract = {Humans and animals have a natural ability to quickly adapt to their surroundings, but machine-learning models, when subjected to changes, often require a complete retraining from scratch. We present Knowledge-adaptation priors (K-priors) to reduce the cost of retraining by enabling quick and accurate adaptation for a wide-variety of tasks and models. This is made possible by a combination of weight and function-space priors to reconstruct the gradients of the past, which recovers and generalizes many existing, but seemingly-unrelated, adaptation strategies. Training with simple first-order gradient methods can often recover the exact retrained model to an arbitrary accuracy by choosing a sufficiently large memory of the past data. Empirical results show that adaptation with K-priors achieves performance similar to full retraining, but only requires training on a handful of past examples.},
  file = {/Users/simon/Zotero/storage/R62KQCGV/Khan and Swaroop - 2021 - Knowledge-Adaptation Priors.pdf}
}

@inproceedings{kohaviStudyCrossValidationBootstrap1995,
  title = {A {{Study}} of {{Cross-Validation}} and {{Bootstrap}} for {{Accuracy Estimation}} and {{Model Selection}}},
  booktitle = {International {{Joint Conference}} on {{Artificial Intelligence}}},
  author = {Kohavi, Ron},
  year = {1995},
  month = aug,
  urldate = {2023-06-10},
  abstract = {We review accuracy estimation methods and compare the two most common methods crossvalidation and bootstrap. Recent experimental results on artificial data and theoretical re cults in restricted settings have shown that for selecting a good classifier from a set of classifiers (model selection), ten-fold cross-validation may be better than the more expensive leaveone-out cross-validation. We report on a largescale experiment--over half a million runs of C4.5 and a Naive-Bayes algorithm--to estimate the effects of different parameters on these algrithms on real-world datasets. For crossvalidation we vary the number of folds and whether the folds are stratified or not, for bootstrap, we vary the number of bootstrap samples. Our results indicate that for real-word datasets similar to ours, The best method to use for model selection is ten fold stratified cross validation even if computation power allows using more folds.},
  note = {[TLDR] The results indicate that for real-word datasets similar to the authors', the best method to use for model selection is ten fold stratified cross validation even if computation power allows using more folds.},
  file = {/Users/simon/Zotero/storage/3GFTC967/Kohavi - 1995 - A Study of Cross-Validation and Bootstrap for Accu.pdf}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2023-08-28},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\textbackslash\% and 18.9\textbackslash\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/Users/simon/Zotero/storage/HYEP3CR7/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf}
}

@article{lakhaniDeepLearningChest2017,
  title = {Deep {{Learning}} at {{Chest Radiography}}: {{Automated Classification}} of {{Pulmonary Tuberculosis}} by {{Using Convolutional Neural Networks}}},
  shorttitle = {Deep {{Learning}} at {{Chest Radiography}}},
  author = {Lakhani, Paras and Sundaram, Baskaran},
  year = {2017},
  month = aug,
  journal = {Radiology},
  volume = {284},
  number = {2},
  pages = {574--582},
  publisher = {{Radiological Society of North America}},
  issn = {0033-8419},
  doi = {10.1148/radiol.2017162326},
  urldate = {2023-08-29},
  abstract = {Purpose To evaluate the efficacy of deep convolutional neural networks (DCNNs) for detecting tuberculosis (TB) on chest radiographs. Materials and Methods Four deidentified HIPAA-compliant datasets were used in this study that were exempted from review by the institutional review board, which consisted of 1007 posteroanterior chest radiographs. The datasets were split into training (68.0\%), validation (17.1\%), and test (14.9\%). Two different DCNNs, AlexNet and GoogLeNet, were used to classify the images as having manifestations of pulmonary TB or as healthy. Both untrained and pretrained networks on ImageNet were used, and augmentation with multiple preprocessing techniques. Ensembles were performed on the best-performing algorithms. For cases where the classifiers were in disagreement, an independent board-certified cardiothoracic radiologist blindly interpreted the images to evaluate a potential radiologist-augmented workflow. Receiver operating characteristic curves and areas under the curve (AUCs) were used to assess model performance by using the DeLong method for statistical comparison of receiver operating characteristic curves. Results The best-performing classifier had an AUC of 0.99, which was an ensemble of the AlexNet and GoogLeNet DCNNs. The AUCs of the pretrained models were greater than that of the untrained models (P {$<$} .001). Augmenting the dataset further increased accuracy (P values for AlexNet and GoogLeNet were .03 and .02, respectively). The DCNNs had disagreement in 13 of the 150 test cases, which were blindly reviewed by a cardiothoracic radiologist, who correctly interpreted all 13 cases (100\%). This radiologist-augmented approach resulted in a sensitivity of 97.3\% and specificity 100\%. Conclusion Deep learning with DCNNs can accurately classify TB at chest radiography with an AUC of 0.99. A radiologist-augmented approach for cases where there was disagreement among the classifiers further improved accuracy. \textcopyright{} RSNA, 2017}
}

@article{lecunBackpropagationAppliedHandwritten1989,
  title = {Backpropagation {{Applied}} to {{Handwritten Zip Code Recognition}}},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  year = {1989},
  month = dec,
  journal = {Neural Computation},
  volume = {1},
  number = {4},
  pages = {541--551},
  issn = {0899-7667},
  doi = {10.1162/neco.1989.1.4.541},
  abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
  file = {/Users/simon/Zotero/storage/QIPJXM2B/6795724.html}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  urldate = {2022-05-06},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  copyright = {2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  langid = {english},
  keywords = {Computer science,Mathematics and computing},
  file = {/Users/simon/Zotero/storage/ATKZPP5D/nature14539.html}
}

@article{lecunDeepLearning2015a,
  title = {Deep {{Learning}}},
  author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  pages = {436--44},
  doi = {10.1038/nature14539},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  file = {/Users/simon/Zotero/storage/IR7F7HWM/LeCun et al. - 2015 - Deep Learning.pdf}
}

@article{leeClinicalApplicationsContinual2020,
  title = {Clinical Applications of Continual Learning Machine Learning},
  author = {Lee, Cecilia S. and Lee, Aaron Y.},
  year = {2020},
  month = jun,
  journal = {The Lancet Digital Health},
  volume = {2},
  number = {6},
  pages = {e279-e281},
  publisher = {{Elsevier}},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(20)30102-3},
  urldate = {2023-04-25},
  langid = {english},
  pmid = {33328120},
  file = {/Users/simon/Zotero/storage/92XDFWMQ/Lee and Lee - 2020 - Clinical applications of continual learning machin.pdf}
}

@article{liEnhancedBirdDetection2019,
  title = {Enhanced {{Bird Detection}} from {{Low-Resolution Aerial Image Using Deep Neural Networks}}},
  author = {Li, Ce and Zhang, Baochang and Hu, Hanwen and Dai, Jing},
  year = {2019},
  month = jun,
  journal = {Neural Processing Letters},
  volume = {49},
  doi = {10.1007/s11063-018-9871-z},
  abstract = {Bird detection in LR images is essential for the applications of unmanned aerial vehicles. It is still a challenging task because traditional discriminative features in high-resolution (HR) usually disappear in low-resolution (LR) images. Although recent advances in single image super-resolution (SISR) and object detection algorithms have offered unprecedented potential for computer-automated reconstructing LR images and detecting various objects, these algorithms are mainly evaluated using synthetic datasets. It is unclear how these algorithms would perform on bird images acquired in the wild and how we could gauge the progress in the real-time bird detection. This paper presents a novel bird detection framework in LR aerial images using deep neural networks (DNN). We collect a dataset named BIRD-50 and a public dataset named CUB-200 of real bird images with different scale low-resolutions. Using these datasets, we introduce a novel DNN based framework for bird detection in reconstructed HR images, which exploits the mapping function from LR to HR aerial image and detects the birds by the state-of-the-art object feature extraction and localization methods. By systematically analyzing the influence of the resolution reduction on the bird detection, the experimental results indicate that our approach has produced significantly improved detection precision for bird detection by the inclusion of SISR algorithms.},
  file = {/Users/simon/Zotero/storage/S5KA9WSQ/Li et al. - 2019 - Enhanced Bird Detection from Low-Resolution Aerial.pdf}
}

@misc{linFocalLossDense2018,
  title = {Focal {{Loss}} for {{Dense Object Detection}}},
  author = {Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  year = {2018},
  month = feb,
  number = {arXiv:1708.02002},
  eprint = {1708.02002},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1708.02002},
  urldate = {2023-08-28},
  abstract = {The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/7UL9R48T/Lin et al. - 2018 - Focal Loss for Dense Object Detection.pdf;/Users/simon/Zotero/storage/LKWQKNU4/1708.html}
}

@misc{linMicrosoftCOCOCommon2015,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Doll{\'a}r, Piotr},
  year = {2015},
  month = feb,
  number = {arXiv:1405.0312},
  eprint = {1405.0312},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1405.0312},
  urldate = {2023-08-28},
  abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: 1) updated annotation pipeline description and figures; 2) added new section describing datasets splits; 3) updated author list},
  file = {/Users/simon/Zotero/storage/XZQWFD6K/Lin et al. - 2015 - Microsoft COCO Common Objects in Context.pdf}
}

@misc{liuImprovingGeneralizationAdapterBased2023,
  title = {Improving {{Generalization}} of {{Adapter-Based Cross-lingual Transfer}} with {{Scheduled Unfreezing}}},
  author = {Liu, Chen Cecilia and Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna},
  year = {2023},
  month = jan,
  number = {arXiv:2301.05487},
  eprint = {2301.05487},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-14},
  abstract = {Standard fine-tuning of language models typically performs well on in-distribution data, but suffers with generalization to distribution shifts. In this work, we aim to improve generalization of adapter-based cross-lingual task transfer where such cross-language distribution shifts are imminent. We investigate scheduled unfreezing algorithms -- originally proposed to mitigate catastrophic forgetting in transfer learning -- for fine-tuning task adapters in cross-lingual transfer. Our experiments show that scheduled unfreezing methods close the gap to full fine-tuning and achieve state-of-the-art transfer performance, suggesting that these methods can go beyond just mitigating catastrophic forgetting. Next, aiming to delve deeper into those empirical findings, we investigate the learning dynamics of scheduled unfreezing using Fisher Information. Our in-depth experiments reveal that scheduled unfreezing induces different learning dynamics compared to standard fine-tuning, and provide evidence that the dynamics of Fisher Information during training correlate with cross-lingual generalization performance. We additionally propose a general scheduled unfreezing algorithm that achieves an average of 2 points improvement over four datasets compared to standard fine-tuning and provides strong empirical evidence for a theory-based justification of the heuristic unfreezing schedule (i.e., the heuristic schedule is implicitly maximizing Fisher Information). Our code will be publicly available.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simon/Zotero/storage/PFUK377H/Liu et al. - 2023 - Improving Generalization of Adapter-Based Cross-li.pdf;/Users/simon/Zotero/storage/292Q6GYU/2301.html}
}

@misc{liuInfluenceSelectionActive2021,
  title = {Influence {{Selection}} for {{Active Learning}}},
  author = {Liu, Zhuoming and Ding, Hao and Zhong, Huaping and Li, Weijia and Dai, Jifeng and He, Conghui},
  year = {2021},
  month = aug,
  number = {arXiv:2108.09331},
  eprint = {2108.09331},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2108.09331},
  urldate = {2023-08-23},
  abstract = {The existing active learning methods select the samples by evaluating the sample's uncertainty or its effect on the diversity of labeled datasets based on different task-specific or model-specific criteria. In this paper, we propose the Influence Selection for Active Learning(ISAL) which selects the unlabeled samples that can provide the most positive Influence on model performance. To obtain the Influence of the unlabeled sample in the active learning scenario, we design the Untrained Unlabeled sample Influence Calculation(UUIC) to estimate the unlabeled sample's expected gradient with which we calculate its Influence. To prove the effectiveness of UUIC, we provide both theoretical and experimental analyses. Since the UUIC just depends on the model gradients, which can be obtained easily from any neural network, our active learning algorithm is task-agnostic and model-agnostic. ISAL achieves state-of-the-art performance in different active learning settings for different tasks with different datasets. Compared with previous methods, our method decreases the annotation cost at least by 12\%, 13\% and 16\% on CIFAR10, VOC2012 and COCO, respectively.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  note = {Comment: ICCV2021 accepted paper},
  file = {/Users/simon/Zotero/storage/D3URHFBR/Liu et al. - 2021 - Influence Selection for Active Learning.pdf;/Users/simon/Zotero/storage/2GEXE8VD/2108.html}
}

@misc{liuPrimerZerothOrderOptimization2020,
  title = {A {{Primer}} on {{Zeroth-Order Optimization}} in {{Signal Processing}} and {{Machine Learning}}},
  author = {Liu, Sijia and Chen, Pin-Yu and Kailkhura, Bhavya and Zhang, Gaoyuan and Hero, Alfred and Varshney, Pramod K.},
  year = {2020},
  month = jun,
  number = {arXiv:2006.06224},
  eprint = {2006.06224},
  primaryclass = {cs, eess, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.06224},
  urldate = {2023-05-16},
  abstract = {Zeroth-order (ZO) optimization is a subset of gradient-free optimization that emerges in many signal processing and machine learning applications. It is used for solving optimization problems similarly to gradient-based methods. However, it does not require the gradient, using only function evaluations. Specifically, ZO optimization iteratively performs three major steps: gradient estimation, descent direction computation, and solution update. In this paper, we provide a comprehensive review of ZO optimization, with an emphasis on showing the underlying intuition, optimization principles and recent advances in convergence analysis. Moreover, we demonstrate promising applications of ZO optimization, such as evaluating robustness and generating explanations from black-box deep learning models, and efficient online sensor management.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Statistics - Machine Learning},
  note = {Comment: IEEE Signal Processing Magazine},
  file = {/Users/simon/Zotero/storage/8XL74NS3/Liu et al. - 2020 - A Primer on Zeroth-Order Optimization in Signal Pr.pdf;/Users/simon/Zotero/storage/9SUMGBDZ/2006.html}
}

@misc{liuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  number = {arXiv:1907.11692},
  eprint = {1907.11692},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.11692},
  urldate = {2023-06-10},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simon/Zotero/storage/MIALQXJS/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf;/Users/simon/Zotero/storage/LPMS8ZQC/1907.html}
}

@misc{LiuSsdSingle,
  title = {Liu: {{Ssd}}: {{Single}} Shot Multibox Detector - {{Google Scholar}}},
  urldate = {2023-08-29},
  howpublished = {https://scholar.google.com/scholar\_lookup?title=SSD\%3A\%20Single\%20Shot\%20Multibox\%20Detector\&publication\_year=2016\&author=W.\%20Liu}
}

@misc{liWhyRobustGeneralization2022,
  title = {Why {{Robust Generalization}} in {{Deep Learning}} Is {{Difficult}}: {{Perspective}} of {{Expressive Power}}},
  shorttitle = {Why {{Robust Generalization}} in {{Deep Learning}} Is {{Difficult}}},
  author = {Li, Binghui and Jin, Jikai and Zhong, Han and Hopcroft, John E. and Wang, Liwei},
  year = {2022},
  month = oct,
  number = {arXiv:2205.13863},
  eprint = {2205.13863},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.13863},
  urldate = {2023-05-16},
  abstract = {It is well-known that modern neural networks are vulnerable to adversarial examples. To mitigate this problem, a series of robust learning algorithms have been proposed. However, although the robust training error can be near zero via some methods, all existing algorithms lead to a high robust generalization error. In this paper, we provide a theoretical understanding of this puzzling phenomenon from the perspective of expressive power for deep neural networks. Specifically, for binary classification problems with well-separated data, we show that, for ReLU networks, while mild over-parameterization is sufficient for high robust training accuracy, there exists a constant robust generalization gap unless the size of the neural network is exponential in the data dimension \$d\$. This result holds even if the data is linear separable (which means achieving standard generalization is easy), and more generally for any parameterized function classes as long as their VC dimension is at most polynomial in the number of parameters. Moreover, we establish an improved upper bound of \$\textbackslash exp(\{\textbackslash mathcal\{O\}\}(k))\$ for the network size to achieve low robust generalization error when the data lies on a manifold with intrinsic dimension \$k\$ (\$k \textbackslash ll d\$). Nonetheless, we also have a lower bound that grows exponentially with respect to \$k\$ -- the curse of dimensionality is inevitable. By demonstrating an exponential separation between the network size for achieving low robust training and generalization error, our results reveal that the hardness of robust generalization may stem from the expressive power of practical models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: 25 pages; to appear in NeurIPS 2022},
  file = {/Users/simon/Zotero/storage/MCPP9IRR/Li et al. - 2022 - Why Robust Generalization in Deep Learning is Diff.pdf;/Users/simon/Zotero/storage/B77NGZ49/2205.html}
}

@article{LocalizationStrokeLesion2022,
  title = {Localization of Stroke Lesion in {{MRI}} Images Using Object Detection Techniques: {{A}} Comprehensive Review},
  shorttitle = {Localization of Stroke Lesion in {{MRI}} Images Using Object Detection Techniques},
  year = {2022},
  month = sep,
  journal = {Neuroscience Informatics},
  volume = {2},
  number = {3},
  pages = {100070},
  publisher = {{Elsevier}},
  issn = {2772-5286},
  doi = {10.1016/j.neuri.2022.100070},
  urldate = {2023-08-29},
  abstract = {Stroke is one of the lethal diseases that has significant negative impact on an individual's life. To diagnose stroke, MRI images play an important ro\ldots},
  langid = {english},
  file = {/Users/simon/Zotero/storage/SYPXTS7B/2022 - Localization of stroke lesion in MRI images using .pdf;/Users/simon/Zotero/storage/538DQ3WJ/S2772528622000322.html}
}

@article{loeyFightingCOVID19Novel2021,
  title = {Fighting against {{COVID-19}}: {{A}} Novel Deep Learning Model Based on {{YOLO-v2}} with {{ResNet-50}} for Medical Face Mask Detection},
  shorttitle = {Fighting against {{COVID-19}}},
  author = {Loey, Mohamed and Manogaran, Gunasekaran and Taha, Mohamed Hamed N. and Khalifa, Nour Eldeen M.},
  year = {2021},
  month = feb,
  journal = {Sustainable Cities and Society},
  volume = {65},
  pages = {102600},
  issn = {22106707},
  doi = {10.1016/j.scs.2020.102600},
  urldate = {2023-08-29},
  abstract = {Semantic Scholar extracted view of "Fighting against COVID-19: A novel deep learning model based on YOLO-v2 with ResNet-50 for medical face mask detection" by Mohamed Loey et al.},
  langid = {english},
  file = {/Users/simon/Zotero/storage/GV2ZICDI/Loey et al. - 2021 - Fighting against COVID-19 A novel deep learning m.pdf}
}

@article{macias-escrivaSelfadaptiveSystemsSurvey2013,
  title = {Self-Adaptive Systems: {{A}} Survey of Current Approaches, Research Challenges and Applications},
  shorttitle = {Self-Adaptive Systems},
  author = {{Mac{\'i}as-Escriv{\'a}}, Frank D. and Haber, Rodolfo and {del Toro}, Raul and Hernandez, Vicente},
  year = {2013},
  month = dec,
  journal = {Expert Systems with Applications},
  volume = {40},
  number = {18},
  pages = {7267--7279},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2013.07.033},
  urldate = {2023-08-30},
  abstract = {Self-adaptive software is capable of evaluating and changing its own behavior, whenever the evaluation shows that the software is not accomplishing what it was intended to do, or when better functionality or performance may be possible. The topic of system adaptivity has been widely studied since the mid-60s and, over the past decade, several application areas and technologies relating to self-adaptivity have assumed greater importance. In all these initiatives, software has become the common element that introduces self-adaptability. Thus, the investigation of systematic software engineering approaches is necessary, in order to develop self-adaptive systems that may ideally be applied across multiple domains. The main goal of this study is to review recent progress on self-adaptivity from the standpoint of computer sciences and cybernetics, based on the analysis of state-of-the-art approaches reported in the literature. This review provides an over-arching, integrated view of computer science and software engineering foundations. Moreover, various methods and techniques currently applied in the design of self-adaptive systems are analyzed, as well as some European research initiatives and projects. Finally, the main bottlenecks for the effective application of self-adaptive technology, as well as a set of key research issues on this topic, are precisely identified, in order to overcome current constraints on the effective application of self-adaptivity in its emerging areas of application.},
  keywords = {Decision-making,Feedback loops,Goal-based model,Model-driven development,Self-adaptive software,Software reflection},
  file = {/Users/simon/Zotero/storage/PB66NVM3/S0957417413005125.html}
}

@misc{madryDeepLearningModels2019,
  title = {Towards {{Deep Learning Models Resistant}} to {{Adversarial Attacks}}},
  author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  year = {2019},
  month = sep,
  number = {arXiv:1706.06083},
  eprint = {1706.06083},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.06083},
  urldate = {2023-05-16},
  abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  note = {Comment: ICLR'18},
  file = {/Users/simon/Zotero/storage/2R7W3QL7/Madry et al. - 2019 - Towards Deep Learning Models Resistant to Adversar.pdf;/Users/simon/Zotero/storage/LH55V63C/1706.html}
}

@incollection{mccloskeyCatastrophicInterferenceConnectionist1989,
  title = {Catastrophic {{Interference}} in {{Connectionist Networks}}: {{The Sequential Learning Problem}}},
  shorttitle = {Catastrophic {{Interference}} in {{Connectionist Networks}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {McCloskey, Michael and Cohen, Neal J.},
  editor = {Bower, Gordon H.},
  year = {1989},
  month = jan,
  volume = {24},
  pages = {109--165},
  publisher = {{Academic Press}},
  doi = {10.1016/S0079-7421(08)60536-8},
  urldate = {2023-08-30},
  abstract = {Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.},
  file = {/Users/simon/Zotero/storage/TCTTAVI8/S0079742108605368.html}
}

@misc{MentalRiskES2023,
  title = {{{MentalRiskES}} 2023},
  urldate = {2023-05-30},
  abstract = {Early detection of mental disorders risk in Spanish},
  howpublished = {https://sites.google.com/view/mentalriskes/home},
  langid = {british},
  file = {/Users/simon/Zotero/storage/TJJZQRMX/home.html}
}

@misc{MentalRiskIberLEF2023,
  title = {{{MentalRisk IberLEF2023}}},
  urldate = {2023-06-08},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/project/646b7f680d0709347d53a6fd},
  langid = {english},
  file = {/Users/simon/Zotero/storage/URI4Y6FI/646b7f680d0709347d53a6fd.html}
}

@misc{MentalRiskIberLEF2023a,
  title = {{{MentalRisk IberLEF2023}}},
  urldate = {2023-06-10},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/project/646b7f680d0709347d53a6fd},
  langid = {english},
  file = {/Users/simon/Zotero/storage/R5UF82UR/646b7f680d0709347d53a6fd.html}
}

@article{mermillodStabilityplasticityDilemmaInvestigating2013,
  title = {The Stability-Plasticity Dilemma: Investigating the Continuum from Catastrophic Forgetting to Age-Limited Learning Effects},
  shorttitle = {The Stability-Plasticity Dilemma},
  author = {Mermillod, Martial and Bugaiska, Aur{\'e}lia and BONIN, Patrick},
  year = {2013},
  journal = {Frontiers in Psychology},
  volume = {4},
  issn = {1664-1078},
  urldate = {2023-08-30},
  file = {/Users/simon/Zotero/storage/6GGX534T/Mermillod et al. - 2013 - The stability-plasticity dilemma investigating th.pdf}
}

@misc{nascimentoSelfAdaptiveLargeLanguage2023,
  title = {Self-{{Adaptive Large Language Model}} ({{LLM}})-{{Based Multiagent Systems}}},
  author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
  year = {2023},
  month = jul,
  number = {arXiv:2307.06187},
  eprint = {2307.06187},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-08-27},
  abstract = {In autonomic computing, self-adaptation has been proposed as a fundamental paradigm to manage the complexity of multiagent systems (MASs). This achieved by extending a system with support to monitor and adapt itself to achieve specific concerns of interest. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, improving the expressiveness of the interaction communication with MASs is not without challenges. In this sense, the interplay between self-adaptive systems and effective communication is crucial for future MAS advancements. In this paper, we propose the integration of large language models (LLMs) such as GPT-based technologies into multiagent systems. We anchor our methodology on the MAPE-K model, which is renowned for its robust support in monitoring, analyzing, planning, and executing system adaptations in response to dynamic environments. We also present a practical illustration of the proposed approach, in which we implement and assess a basic MAS-based application. The approach significantly advances the state-of-the-art of self-adaptive systems by proposing a new paradigm for MAS self-adaptation of autonomous systems based on LLM capabilities.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Multiagent Systems},
  note = {Comment: 6 pages, submitted},
  file = {/Users/simon/Zotero/storage/PU9GI23T/Nascimento et al. - 2023 - Self-Adaptive Large Language Model (LLM)-Based Mul.pdf;/Users/simon/Zotero/storage/3URLWRBJ/2307.html}
}

@inproceedings{osmanDetectionMycobacteriumTuberculosis2010,
  title = {Detection of Mycobacterium Tuberculosis in {{Ziehl-Neelsen}} Stained Tissue Images Using {{Zernike}} Moments and Hybrid Multilayered Perceptron Network},
  booktitle = {2010 {{IEEE International Conference}} on {{Systems}}, {{Man}} and {{Cybernetics}}},
  author = {Osman, M. K. and Mashor, M. Y. and Jaafar, H.},
  year = {2010},
  month = oct,
  pages = {4049--4055},
  issn = {1062-922X},
  doi = {10.1109/ICSMC.2010.5642191},
  abstract = {Conventional clinical diagnosis of tuberculosis disease such as manual screening by microbiologist are tedious, laborious and time consuming. Therefore, more research has been carried out to develop technologies that able to automate the detection process. This paper presents an automated approach to tuberculosis bacilli detection in tissue section. The proposed approach employs image processing technique and neural network for the segmentation and detection of tuberculosis bacilli. First, images of tuberculosis bacilli in tissue samples are captured using light microscope after stained with Ziehl-Neelsen staining method. Then colour image segmentation using moving k-mean clustering is used to extract tuberculosis bacilli from the tissue image. Two colour spaces, RGB and C-Y colour, were utilised in order to improve the quality of segmentation and robust against various staining condition. Next, geometrical features of Zernike moments are calculated. From these features, the best features that could detect tuberculosis bacilli with higher accuracy were selected using hybrid multilayered perceptron network. Experimental results demonstrate that the proposed method is efficient and accurate to detect the tubercle bacilli in tissue.},
  keywords = {Accuracy,Equations,hybrid multilayered perceptron network,Image segmentation,Neural networks,Robustness,tissue section,tuberculosis,Zernike moment}
}

@article{panSurveyTransferLearning2010,
  title = {A {{Survey}} on {{Transfer Learning}}},
  author = {Pan, Sinno Jialin and Yang, Qiang},
  year = {2010},
  month = oct,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {22},
  number = {10},
  pages = {1345--1359},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2009.191},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
  keywords = {Data mining,data mining.,Knowledge engineering,Knowledge transfer,Labeling,Learning systems,machine learning,Machine learning,Machine learning algorithms,Space technology,survey,Testing,Training data,Transfer learning}
}

@misc{PapersCodeEvaluation,
  title = {Papers with {{Code}} - {{Evaluation}} of Sentence Embeddings in Downstream and Linguistic Probing Tasks},
  urldate = {2023-06-12},
  abstract = {Implemented in 14 code libraries.},
  howpublished = {https://paperswithcode.com/paper/evaluation-of-sentence-embeddings-in},
  langid = {english}
}

@misc{PapersCodeLoss,
  title = {Papers with {{Code}} - {{Loss}} of {{Plasticity}} in {{Deep Continual Learning}}},
  urldate = {2023-08-30},
  abstract = {Implemented in one code library.},
  howpublished = {https://paperswithcode.com/paper/maintaining-plasticity-in-deep-continual},
  langid = {english}
}

@article{parisiContinualLifelongLearning2019,
  title = {Continual {{Lifelong Learning}} with {{Neural Networks}}: {{A Review}}},
  shorttitle = {Continual {{Lifelong Learning}} with {{Neural Networks}}},
  author = {Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan},
  year = {2019},
  month = may,
  journal = {Neural Networks},
  volume = {113},
  eprint = {1802.07569},
  primaryclass = {cs, q-bio, stat},
  pages = {54--71},
  issn = {08936080},
  doi = {10.1016/j.neunet.2019.01.012.},
  urldate = {2023-08-27},
  abstract = {Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/2KT42DXG/Parisi et al. - 2019 - Continual Lifelong Learning with Neural Networks .pdf;/Users/simon/Zotero/storage/CEQZQ3PG/1802.html}
}

@misc{parkTRAKAttributingModel2023,
  title = {{{TRAK}}: {{Attributing Model Behavior}} at {{Scale}}},
  shorttitle = {{{TRAK}}},
  author = {Park, Sung Min and Georgiev, Kristian and Ilyas, Andrew and Leclerc, Guillaume and Madry, Aleksander},
  year = {2023},
  month = apr,
  number = {arXiv:2303.14186},
  eprint = {2303.14186},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2303.14186},
  urldate = {2023-05-18},
  abstract = {The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets. In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scales: image classifiers trained on ImageNet, vision-language models (CLIP), and language models (BERT and mT5). We provide code for using TRAK (and reproducing our work) at https://github.com/MadryLab/trak .},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/3ICJEL7L/Park et al. - 2023 - TRAK Attributing Model Behavior at Scale.pdf;/Users/simon/Zotero/storage/BAYS6HC2/2303.html}
}

@misc{parkTRAKAttributingModel2023a,
  title = {{{TRAK}}: {{Attributing Model Behavior}} at {{Scale}}},
  shorttitle = {{{TRAK}}},
  author = {Park, Sung Min and Georgiev, Kristian and Ilyas, Andrew and Leclerc, Guillaume and Madry, Aleksander},
  year = {2023},
  month = apr,
  number = {arXiv:2303.14186},
  eprint = {2303.14186},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-18},
  abstract = {The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets. In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scales: image classifiers trained on ImageNet, vision-language models (CLIP), and language models (BERT and mT5). We provide code for using TRAK (and reproducing our work) at https://github.com/MadryLab/trak.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/simon/Zotero/storage/PH5PE69T/Park et al. - 2023 - TRAK Attributing Model Behavior at Scale.pdf}
}

@misc{peroneEvaluationSentenceEmbeddings2018,
  title = {Evaluation of Sentence Embeddings in Downstream and Linguistic Probing Tasks},
  author = {Perone, Christian S. and Silveira, Roberto and Paula, Thomas S.},
  year = {2018},
  month = jun,
  number = {arXiv:1806.06259},
  eprint = {1806.06259},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-06-12},
  abstract = {Despite the fast developmental pace of new sentence embedding methods, it is still challenging to find comprehensive evaluations of these different techniques. In the past years, we saw significant improvements in the field of sentence embeddings and especially towards the development of universal sentence encoders that could provide inductive transfer to a wide variety of downstream tasks. In this work, we perform a comprehensive evaluation of recent methods using a wide variety of downstream and linguistic feature probing tasks. We show that a simple approach using bag-of-words with a recently introduced language model for deep context-dependent word embeddings proved to yield better results in many tasks when compared to sentence encoders trained on entailment datasets. We also show, however, that we are still far away from a universal encoder that can perform consistently across several downstream tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  note = {Comment: 15 pages, 3 figures, 11 tables},
  file = {/Users/simon/Zotero/storage/2R9N5G2F/Perone et al. - 2018 - Evaluation of sentence embeddings in downstream an.pdf;/Users/simon/Zotero/storage/NF3I9FDI/1806.html}
}

@misc{phangSentenceEncodersSTILTs2019,
  title = {Sentence {{Encoders}} on {{STILTs}}: {{Supplementary Training}} on {{Intermediate Labeled-data Tasks}}},
  shorttitle = {Sentence {{Encoders}} on {{STILTs}}},
  author = {Phang, Jason and F{\'e}vry, Thibault and Bowman, Samuel R.},
  year = {2019},
  month = feb,
  number = {arXiv:1811.01088},
  eprint = {1811.01088},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1811.01088},
  urldate = {2023-05-31},
  abstract = {Pretraining sentence encoders with language modeling and related unsupervised tasks has recently been shown to be very effective for language understanding tasks. By supplementing language model-style pretraining with further training on data-rich supervised tasks, such as natural language inference, we obtain additional performance improvements on the GLUE benchmark. Applying supplementary training on BERT (Devlin et al., 2018), we attain a GLUE score of 81.8---the state of the art (as of 02/24/2019) and a 1.4 point improvement over BERT. We also observe reduced variance across random restarts in this setting. Our approach yields similar improvements when applied to ELMo (Peters et al., 2018a) and Radford et al. (2018)'s model. In addition, the benefits of supplementary training are particularly pronounced in data-constrained regimes, as we show in experiments with artificially limited training data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/simon/Zotero/storage/39RMQD25/Phang et al. - 2019 - Sentence Encoders on STILTs Supplementary Trainin.pdf;/Users/simon/Zotero/storage/8HAE984S/1811.html}
}

@misc{PhilipsHealthcareIncisive,
  title = {{Philips Healthcare | Incisive CT: sistema de CT de tubo de larga duraci\'on: vMRC}},
  shorttitle = {{Philips Healthcare | Incisive CT}},
  journal = {Philips},
  urldate = {2023-08-26},
  abstract = {Inteligencia en cada paso.},
  howpublished = {https://www.philips.es/healthcare/product/HC728143/incisive-ct-ct-scanner},
  langid = {spanish}
}

@article{queralt-rosinachApplyingFAIRPrinciples2022,
  title = {Applying the {{FAIR}} Principles to Data in a Hospital: Challenges and Opportunities in a Pandemic},
  shorttitle = {Applying the {{FAIR}} Principles to Data in a Hospital},
  author = {{Queralt-Rosinach}, N{\'u}ria and Kaliyaperumal, Rajaram and Bernab{\'e}, C{\'e}sar H. and Long, Qinqin and Joosten, Simone A. and {van der Wijk}, Henk Jan and Flikkenschild, Erik L.A. and Burger, Kees and Jacobsen, Annika and Mons, Barend and Roos, Marco and {BEAT-COVID Group} and {COVID-19 LUMC Group}},
  year = {2022},
  month = apr,
  journal = {Journal of Biomedical Semantics},
  volume = {13},
  number = {1},
  pages = {12},
  issn = {2041-1480},
  doi = {10.1186/s13326-022-00263-7},
  urldate = {2023-01-31},
  abstract = {The COVID-19 pandemic has challenged healthcare systems and research worldwide. Data is collected all over the world and needs to be integrated and made available to other researchers quickly. However, the various heterogeneous information systems that are used in hospitals can result in fragmentation of health data over multiple data `silos' that are not interoperable for analysis. Consequently, clinical observations in hospitalised patients are not prepared to be reused efficiently and timely. There is a need to adapt the research data management in hospitals to make COVID-19 observational patient data machine actionable, i.e. more Findable, Accessible, Interoperable and Reusable (FAIR) for humans and machines. We therefore applied the FAIR principles in the hospital to make patient data more FAIR.},
  keywords = {FAIR,Hospital,Ontologies,Open science,Patient data,Research data management},
  file = {/Users/simon/Zotero/storage/TVDIFFFG/Queralt-Rosinach et al. - 2022 - Applying the FAIR principles to data in a hospital.pdf;/Users/simon/Zotero/storage/TC5AHL93/s13326-022-00263-7.html}
}

@book{redbooksPracticalGuideIBM2004,
  title = {A {{Practical Guide}} to the {{IBM Autonomic Computing Toolkit}}},
  author = {Redbooks, I. B. M.},
  year = {2004},
  publisher = {{IBM, International Support Organization}},
  googlebooks = {XHeoSgAACAAJ},
  isbn = {978-0-7384-9805-8},
  langid = {english},
  keywords = {Computers / Programming / General,Technology \& Engineering / Reference}
}

@misc{redmonYOLO9000BetterFaster2016,
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  year = {2016},
  month = dec,
  number = {arXiv:1612.08242},
  eprint = {1612.08242},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1612.08242},
  urldate = {2023-08-28},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/NGNGUQ2S/Redmon and Farhadi - 2016 - YOLO9000 Better, Faster, Stronger.pdf;/Users/simon/Zotero/storage/WZQGI26H/1612.html}
}

@misc{redmonYOLOv3IncrementalImprovement2018,
  title = {{{YOLOv3}}: {{An Incremental Improvement}}},
  shorttitle = {{{YOLOv3}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  year = {2018},
  month = apr,
  number = {arXiv:1804.02767},
  eprint = {1804.02767},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1804.02767},
  urldate = {2023-08-28},
  abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that's pretty swell. It's a little bigger than last time but more accurate. It's still fast though, don't worry. At 320x320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 mAP@50 in 51 ms on a Titan X, compared to 57.5 mAP@50 in 198 ms by RetinaNet, similar performance but 3.8x faster. As always, all the code is online at https://pjreddie.com/yolo/},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: Tech Report},
  file = {/Users/simon/Zotero/storage/88L3JL8A/Redmon and Farhadi - 2018 - YOLOv3 An Incremental Improvement.pdf;/Users/simon/Zotero/storage/ITSMK9T2/1804.html}
}

@misc{redmonYouOnlyLook2016,
  title = {You {{Only Look Once}}: {{Unified}}, {{Real-Time Object Detection}}},
  shorttitle = {You {{Only Look Once}}},
  author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  year = {2016},
  month = may,
  number = {arXiv:1506.02640},
  eprint = {1506.02640},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1506.02640},
  urldate = {2023-08-28},
  abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/KPRKHNZT/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Dete.pdf;/Users/simon/Zotero/storage/2FWDUSTM/1506.html}
}

@misc{reisserFederatedMixtureExperts2021,
  title = {Federated {{Mixture}} of {{Experts}}},
  author = {Reisser, Matthias and Louizos, Christos and Gavves, Efstratios and Welling, Max},
  year = {2021},
  month = jul,
  number = {arXiv:2107.06724},
  eprint = {2107.06724},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-25},
  abstract = {Federated learning (FL) has emerged as the predominant approach for collaborative training of neural network models across multiple users, without the need to gather the data at a central location. One of the important challenges in this setting is data heterogeneity, i.e. different users have different data characteristics. For this reason, training and using a single global model might be suboptimal when considering the performance of each of the individual user's data. In this work, we tackle this problem via Federated Mixture of Experts, FedMix, a framework that allows us to train an ensemble of specialized models. FedMix adaptively selects and trains a user-specific selection of the ensemble members. We show that users with similar data characteristics select the same members and therefore share statistical strength while mitigating the effect of non-i.i.d data. Empirically, we show through an extensive experimental evaluation that FedMix improves performance compared to using a single global model across a variety of different sources of non-i.i.d.-ness.},
  archiveprefix = {arxiv},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Machine Learning},
  file = {/Users/simon/Zotero/storage/8AAGDKPN/Reisser et al. - 2021 - Federated Mixture of Experts.pdf;/Users/simon/Zotero/storage/7WKHXAEH/2107.html}
}

@misc{renFasterRCNNRealTime2016,
  title = {Faster {{R-CNN}}: {{Towards Real-Time Object Detection}} with {{Region Proposal Networks}}},
  shorttitle = {Faster {{R-CNN}}},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  year = {2016},
  month = jan,
  number = {arXiv:1506.01497},
  eprint = {1506.01497},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1506.01497},
  urldate = {2023-08-28},
  abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: Extended tech report},
  file = {/Users/simon/Zotero/storage/MZAEMELS/Ren et al. - 2016 - Faster R-CNN Towards Real-Time Object Detection w.pdf;/Users/simon/Zotero/storage/KCWS9DZM/1506.html}
}

@article{royDeepLearningClassification2020,
  title = {Deep {{Learning}} for {{Classification}} and {{Localization}} of {{COVID-19 Markers}} in {{Point-of-Care Lung Ultrasound}}},
  author = {Roy, Subhankar and Menapace, Willi and Oei, Sebastiaan and Luijten, Ben and Fini, Enrico and Saltori, Cristiano and Huijben, Iris and Chennakeshava, Nishith and Mento, Federico and Sentelli, Alessandro and Peschiera, Emanuele and Trevisan, Riccardo and Maschietto, Giovanni and Torri, Elena and Inchingolo, Riccardo and Smargiassi, Andrea and Soldati, Gino and Rota, Paolo and Passerini, Andrea and Van Sloun, Ruud J. G. and Ricci, Elisa and Demi, Libertario},
  year = {2020},
  month = aug,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {39},
  number = {8},
  pages = {2676--2687},
  issn = {0278-0062, 1558-254X},
  doi = {10.1109/TMI.2020.2994459},
  urldate = {2023-08-29},
  abstract = {Deep learning (DL) has proved successful in medical imaging and, in the wake of the recent COVID-19 pandemic, some works have started to investigate DL-based solutions for the assisted diagnosis of lung diseases. While existing works focus on CT scans, this paper studies the application of DL techniques for the analysis of lung ultrasonography (LUS) images. Specifically, we present a novel fully-annotated dataset of LUS images collected from several Italian hospitals, with labels indicating the degree of disease severity at a frame-level, video-level, and pixel-level (segmentation masks). Leveraging these data, we introduce several deep models that address relevant tasks for the automatic analysis of LUS images. In particular, we present a novel deep network, derived from Spatial Transformer Networks, which simultaneously predicts the disease severity score associated to a input frame and provides localization of pathological artefacts in a weakly-supervised way. Furthermore, we introduce a new method based on uninorms for effective frame score aggregation at a video-level. Finally, we benchmark state of the art deep models for estimating pixel-level segmentations of COVID-19 imaging biomarkers. Experiments on the proposed dataset demonstrate satisfactory results on all the considered tasks, paving the way to future research on DL for the assisted diagnosis of COVID-19 from LUS data.},
  note = {[TLDR] A novel deep network, derived from Spatial Transformer Networks, is presented, which simultaneously predicts the disease severity score associated to a input frame and provides localization of pathological artefacts in a weakly-supervised way.},
  file = {/Users/simon/Zotero/storage/TX9EA789/Roy et al. - 2020 - Deep Learning for Classification and Localization .pdf}
}

@misc{schuldSupervisedQuantumMachine2021,
  title = {Supervised Quantum Machine Learning Models Are Kernel Methods,},
  author = {Schuld, Maria},
  year = {2021},
  month = apr,
  number = {arXiv:2101.11020},
  eprint = {2101.11020},
  primaryclass = {quant-ph, stat},
  publisher = {{arXiv}},
  urldate = {2023-05-25},
  abstract = {With near-term quantum devices available and the race for fault-tolerant quantum computers in full swing, researchers became interested in the question of what happens if we replace a supervised machine learning model with a quantum circuit. While such "quantum models" are sometimes called "quantum neural networks", it has been repeatedly noted that their mathematical structure is actually much more closely related to kernel methods: they analyse data in high-dimensional Hilbert spaces to which we only have access through inner products revealed by measurements. This technical manuscript summarises and extends the idea of systematically rephrasing supervised quantum models as a kernel method. With this, a lot of near-term and fault-tolerant quantum models can be replaced by a general support vector machine whose kernel computes distances between data-encoding quantum states. Kernel-based training is then guaranteed to find better or equally good quantum models than variational circuit training. Overall, the kernel perspective of quantum machine learning tells us that the way that data is encoded into quantum states is the main ingredient that can potentially set quantum models apart from classical machine learning models.},
  archiveprefix = {arxiv},
  keywords = {Quantum Physics,Statistics - Machine Learning},
  note = {Comment: 26 pages, 9 figures - Version 2 emphasises focus on supervised learning, adds more references to existing literature, deletes section on state discrimination due to a technical error, and updates the comparison between kernel-based and variational training},
  file = {/Users/simon/Zotero/storage/4JJCJF66/Schuld - 2021 - Supervised quantum machine learning models are ker.pdf;/Users/simon/Zotero/storage/7RZS9VS8/2101.html}
}

@misc{SpeechLanguageProcessing,
  title = {Speech and {{Language Processing}}},
  urldate = {2023-06-12},
  howpublished = {https://web.stanford.edu/\textasciitilde jurafsky/slp3/},
  file = {/Users/simon/Zotero/storage/JGZ876Y4/slp3.html}
}

@misc{szegedyGoingDeeperConvolutions2014,
  title = {Going {{Deeper}} with {{Convolutions}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  year = {2014},
  month = sep,
  number = {arXiv:1409.4842},
  eprint = {1409.4842},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1409.4842},
  urldate = {2023-08-29},
  abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/simon/Zotero/storage/URBPLWGR/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf;/Users/simon/Zotero/storage/87TZ8X5K/1409.html}
}

@article{thrunLifelongRobotLearning1995,
  title = {Lifelong Robot Learning},
  author = {Thrun, Sebastian and Mitchell, Tom M.},
  year = {1995},
  month = jul,
  journal = {Robotics and Autonomous Systems},
  series = {The {{Biology}} and {{Technology}} of {{Intelligent Autonomous Agents}}},
  volume = {15},
  number = {1},
  pages = {25--46},
  issn = {0921-8890},
  doi = {10.1016/0921-8890(95)00004-Y},
  urldate = {2023-08-27},
  abstract = {Learning provides a useful tool for the automatic design of autonomous robots. Recent research on learning robot control has predominantly focused on learning single tasks that were studied in isolation. If robots encounter a multitude of control learning tasks over their entire lifetime there is an opportunity to transfer knowledge between them. In order to do so, robots may learn the invariants and the regularities of the individual tasks and environments. This task-independent knowledge can be employed to bias generalization when learning control, which reduces the need for real-world experimentation. We argue that knowledge transfer is essential if robots are to learn control with moderate learning times in complex scenarios. Two approaches to lifelong robot learning which both capture invariant knowledge about the robot and its environments are presented. Both approaches have been evaluated using a HERO-2000 mobile robot. Learning tasks included navigation in unknown indoor environments and a simple find-and-fetch task.},
  file = {/Users/simon/Zotero/storage/KNJK9LSF/092188909500004Y.html}
}

@article{topolHighperformanceMedicineConvergence2019,
  title = {High-Performance Medicine: The Convergence of Human and Artificial Intelligence},
  shorttitle = {High-Performance Medicine},
  author = {Topol, Eric J.},
  year = {2019},
  month = jan,
  journal = {Nature Medicine},
  volume = {25},
  number = {1},
  pages = {44--56},
  publisher = {{Nature Publishing Group}},
  issn = {1546-170X},
  doi = {10.1038/s41591-018-0300-7},
  urldate = {2023-08-25},
  abstract = {The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient\textendash doctor relationship or facilitate its erosion remains to be seen.},
  copyright = {2019 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Health care,Machine learning}
}

@article{uijlingsSelectiveSearchObject2013,
  title = {Selective {{Search}} for {{Object Recognition}}},
  author = {Uijlings, J. R. R. and van de Sande, K. E. A. and Gevers, T. and Smeulders, A. W. M.},
  year = {2013},
  journal = {International Journal of Computer Vision},
  volume = {104},
  file = {/Users/simon/Zotero/storage/L432AER2/bibtexbrowser.html}
}

@misc{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = jun,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.03762},
  urldate = {2023-08-28},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  note = {Comment: 15 pages, 5 figures},
  file = {/Users/simon/Zotero/storage/FG3GZLSN/Vaswani et al. - 2023 - Attention Is All You Need.pdf;/Users/simon/Zotero/storage/S669TB6N/1706.html}
}

@article{villegasDesigningSelfAdaptiveSoftware2011,
  title = {On {{Designing Self-Adaptive Software Systems}}},
  author = {Villegas, Norha and M{\"u}ller, Hausi and Tamura, Gabriel},
  year = {2011},
  month = sep,
  journal = {Revista S\&T},
  volume = {9},
  pages = {29--51},
  doi = {10.18046/syt.v9i18.1076},
  abstract = {Self-adaptive systems modify themselves at run-time in order to control the satisfaction of their requirements under changing environmental conditions. Over the past century, feedback-loops have been used as important models for controlling dynamic behavior of mechanical, electrical, fluid and chemical systems in the corresponding fields of engineering. More recently, they also have been adopted for engineering self-adaptive software systems. However, obtaining sound and explicit mappings consistently between adaptive software architectures and feedback loop elements is still an open challenge. This paper, recalling a reference model proposed previously with that goal, discuss key aspects on the design of adaptive software where feedback loop elements are explicitly defined as first-class components in its software architecture. It complements this discussion with an illustration of the process to use this reference model by applying it to a plausible adaptive software example. This paper aims at providing a reference starting point to support software engineers in the process of designing self-adaptive software systems. Resumen Ante condiciones cambiantes del entorno, los sistemas autoadaptativos pueden modificarse a s\'i mismos para controlar la satisfacci\'on de sus requerimientos en tiempo de ejecuci\'on. Durante el siglo pasado los sistemas de retroalimentaci\'on fueron importantes modelos para controlar el comportamiento din\'amico de sistemas mec\'anicos, el\'ectricos, de fluidos y qu\'imicos, en sus respectivos campos de la ingenier\'ia. M\'as recientemente fueron adoptados para dise\~nar software autoadaptativo. No obstante, lograr mapeos coherentes y expl\'icitos consistentemente entre las arquitecturas de software adaptativo y los elementos de sistemas de retroalimentaci\'on es a\'un un reto abierto. Este art\'iculo, sobre un modelo de referencia propuesto con ese prop\'osito, discute aspectos clave del dise\~no de software autoadaptativo, en que los elementos de sistemas de retroalimentaci\'on se definen expl\'icitamente como componentes de primer nivel en su arquitectura. Adicionalmente, ilustra la aplicaci\'on de este modelo de referencia a un ejemplo real de software adaptativo. El art\'iculo ofrece a los ingenieros de software un punto de referencia para iniciar el dise\~no de software autoadaptativo.},
  file = {/Users/simon/Zotero/storage/UTTI7AM5/Villegas et al. - 2011 - On Designing Self-Adaptive Software Systems.pdf}
}

@inproceedings{visunaNovelDeepLearningBased2023,
  title = {Novel {{Deep Learning-Based Technique}} for {{Tuberculosis Bacilli Detection}} in {{Sputum Microscopy}}},
  booktitle = {International {{Conference}} on {{Interactive Collaborative Robotics}}},
  author = {Visu{\~n}a, Lara and {Garcia-Blas}, Javier and Carretero, Jesus},
  year = {2023},
  pages = {269--279},
  publisher = {{Springer}}
}

@article{vokingerContinualLearningMedical2021,
  title = {Continual Learning in Medical Devices: {{FDA}}'s Action Plan and Beyond},
  shorttitle = {Continual Learning in Medical Devices},
  author = {Vokinger, Kerstin N. and Feuerriegel, Stefan and Kesselheim, Aaron S.},
  year = {2021},
  month = jun,
  journal = {The Lancet Digital Health},
  volume = {3},
  number = {6},
  pages = {e337-e338},
  publisher = {{Elsevier}},
  issn = {2589-7500},
  doi = {10.1016/S2589-7500(21)00076-5},
  urldate = {2023-08-30},
  langid = {english},
  pmid = {33933404},
  file = {/Users/simon/Zotero/storage/BQBBYVL6/Vokinger et al. - 2021 - Continual learning in medical devices FDA's actio.pdf}
}

@inproceedings{wangChestXray8HospitalscaleChest2017,
  title = {{{ChestX-ray8}}: {{Hospital-scale Chest X-ray Database}} and {{Benchmarks}} on {{Weakly-Supervised Classification}} and {{Localization}} of {{Common Thorax Diseases}}},
  shorttitle = {{{ChestX-ray8}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M.},
  year = {2017},
  month = jul,
  eprint = {1705.02315},
  primaryclass = {cs},
  pages = {3462--3471},
  doi = {10.1109/CVPR.2017.369},
  urldate = {2023-08-25},
  abstract = {The chest X-ray is one of the most commonly accessible radiological examinations for screening and diagnosis of many lung diseases. A tremendous number of X-ray imaging studies accompanied by radiological reports are accumulated and stored in many modern hospitals' Picture Archiving and Communication Systems (PACS). On the other side, it is still an open question how this type of hospital-size knowledge database containing invaluable imaging informatics (i.e., loosely labeled) can be used to facilitate the data-hungry deep learning paradigms in building truly large-scale high precision computer-aided diagnosis (CAD) systems. In this paper, we present a new chest X-ray database, namely "ChestX-ray8", which comprises 108,948 frontal-view X-ray images of 32,717 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. Importantly, we demonstrate that these commonly occurring thoracic diseases can be detected and even spatially-located via a unified weakly-supervised multi-label image classification and disease localization framework, which is validated using our proposed dataset. Although the initial quantitative results are promising as reported, deep convolutional neural network based "reading chest X-rays" (i.e., recognizing and locating the common disease patterns trained with only image-level labels) remains a strenuous task for fully-automated high precision CAD systems. Data download link: https://nihcc.app.box.com/v/ChestXray-NIHCC},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: CVPR 2017 spotlight;V1: CVPR submission+supplementary; V2: Statistics and benchmark results on published ChestX-ray14 dataset are updated in Appendix B V3: Minor correction V4: new data download link upated: https://nihcc.app.box.com/v/ChestXray-NIHCC V5: Update benchmark results on the published data split in the appendix},
  file = {/Users/simon/Zotero/storage/4JCKTFMR/Wang et al. - 2017 - ChestX-ray8 Hospital-scale Chest X-ray Database a.pdf;/Users/simon/Zotero/storage/9MUSV4X2/1705.html}
}

@inproceedings{wolfTransformersStateoftheArtNatural2020,
  title = {Transformers: {{State-of-the-Art Natural Language Processing}}},
  shorttitle = {Transformers},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}: {{System Demonstrations}}},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Remi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and {von Platen}, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander},
  year = {2020},
  month = oct,
  pages = {38--45},
  publisher = {{Association for Computational Linguistics}},
  address = {{Online}},
  doi = {10.18653/v1/2020.emnlp-demos.6},
  urldate = {2023-06-12},
  abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/huggingface/transformers.},
  file = {/Users/simon/Zotero/storage/R3RPWQXV/Wolf et al. - 2020 - Transformers State-of-the-Art Natural Language Pr.pdf}
}

@misc{WorldHealthReport,
  title = {The {{World Health Report}} 2001: {{Mental Disorders}} Affect One in Four People},
  shorttitle = {The {{World Health Report}} 2001},
  urldate = {2023-05-29},
  abstract = {One in four people in the world will be affected by mental or neurological disorders at some point in their lives. Around 450 million people currently suffer from such conditions, placing mental disorders among the leading causes of ill-health and disability worldwide.Treatments are available, but nearly two-thirds of people with a known mental disorder never seek help from a health professional. Stigma, discrimination and neglect prevent care and treatment from reaching people with mental disorders, says the World Health Organization (WHO). Where there is neglect, there is little or no understanding. Where there is no understanding, there is neglect.In a new report entitled "New Understanding, New Hope" the United Nations' health agency seeks to break this vicious cycle and urges governments to seek solutions for mental health that are already available and affordable. Governments should move away from large mental institutions and towards community health care, and integrate mental health care into primary health care and the general health care system, says WHO."Mental illness is not a personal failure. In fact, if there is failure, it is to be found in the way we have responded to people with mental and brain disorders," said Dr Gro Harlem Brundtland, Director-General of WHO, on releasing the World Health Report. "I hope this report will dispel long-held doubts and dogma and mark the beginning of a new public health era in the field of mental health," she added.A lack of urgency, misinformation, and competing demands are blinding policy-makers from taking stock of a situation where mental disorders fi gure among the leading causes of disease and disability in the world, says WHO. Depressive disorders are already the fourth leading cause of the global disease burden. They are expected to rank second by 2020, behind ischaemic heart disease but ahead of all other diseases.The report invites governments to make strategic decisions and choices in order to bring about positive change in the acceptance and treatment of mental disorders. The report says some mental disorders can be prevented; most mental and behavioural disorders can be successfully treated; and that much of this prevention, cure and treatment is affordable.Despite the chronic and long-term nature of some mental disorders, with the proper treatment, people suffering from mental disorders can live productive lives and be a vital part of their communities. Over 80\% of people with schizophrenia can be free of relapses at the end of one year of treatment with antipsychotic drugs combined with family intervention. Up to 60\% of people with depression can recover with a proper combination of antidepressant drugs and psychotherapy. Up to 70\% of people with epilepsy can be seizure free when treated with simple, inexpensive anticonvulsants.The responsibility for action lies with governments, says WHO. Currently, more than 40\% of countries have no mental health policy and over 30\% have no mental health programme.Around 25\% of countries have no mental health legislation. The magnitude of mental health burden is not matched by the size and effectiveness of the response it demands. Currently, more than 33\% of countries allocate less than 1\% of their total health budgets to mental health, with another 33\% spending just 1\% of their budgets on mental health. A limited range of medicines is suffi cient to treat the majority of mental disorders. About 25\% of countries, however, do not have the three most commonly prescribed drugs used to treat schizophrenia, depression and epilepsy at the primary health care level. There is only one psychiatrist per 100 000 people in over half the countries in the world, and 40\% of countries have less than one hospital bed reserved for mental disorders per 10 000 people.The poor often bear the greater burden of mental disorders, both in terms of the risk in having a mental disorder and the lack of access to treatment. Constant exposure to severely stressful events, dangerous living conditions, exploitation, and poor health in general all contribute to the greater vulnerability of the poor. The lack of access to affordable treatment makes the course of the illness more severe and debilitating, leading to a vicious circle of poverty and mental health disorders that is rarely broken.The report says new knowledge can have a tremendous impact on how individuals, societies and the public health community deal with mental disorders. We now know that large mental institutions no longer represent the best option for patients and families. Such institutions lead to a loss of social skills, excessive restriction, human rights violations, dependency, and reduced opportunities for rehabilitation. Countries should move towards setting up community care alternatives in a planned manner, ensuring that such alternatives are in place even as institutions are being phased out."Science, ethics and experience point to clear paths to follow. In the face of this knowledge, a failure to act will reflect a lack of commitment to address mental health problems," said Dr Benedetto Saraceno, Director of WHO's Mental Health and Substance Dependence department.The policy directions have never been so clear, says WHO. Governments who are just starting to address mental health will need to set priorities. Choices must be made among a large number of services and a wide range of prevention and promotion strategies.WHO's message is that every country, no matter what its resource constraints, can do something to improve the mental health of its people. What it requires is the courage and the commitment to take the necessary steps.The report is part of a year-long campaign on mental health. For the first time, multiple events at WHO including its premier report, technical discussions at the World Health Assembly and World Health Day, have all focused on one topic \textendash{} mental health.},
  howpublished = {https://www.who.int/news/item/28-09-2001-the-world-health-report-2001-mental-disorders-affect-one-in-four-people},
  langid = {english},
  file = {/Users/simon/Zotero/storage/RW3CBQ2B/28-09-2001-the-world-health-report-2001-mental-disorders-affect-one-in-four-people.html}
}

@article{xiaEvolvingKernelExtreme2022,
  title = {Evolving Kernel Extreme Learning Machine for Medical Diagnosis via a Disperse Foraging Sine Cosine Algorithm},
  author = {Xia, Jianfu and Yang, Daqing and Zhou, Hong and Chen, Yuyan and Zhang, Hongliang and Liu, Tong and Heidari, Ali Asghar and Chen, Huiling and Pan, Zhifang},
  year = {2022},
  month = feb,
  journal = {Computers in Biology and Medicine},
  volume = {141},
  pages = {105137},
  issn = {1879-0534},
  doi = {10.1016/j.compbiomed.2021.105137},
  abstract = {Kernel extreme learning machine (KELM) has been widely used in the fields of classification and identification since it was proposed. As the parameters in the KELM model have a crucial impact on performance, they must be optimized before the model can be applied in practical areas. In this study, to improve optimization performance, a new parameter optimization strategy is proposed, based on a disperse foraging sine cosine algorithm (DFSCA), which is utilized to force some portions of search agents to explore other potential regions. Meanwhile, DFSCA is integrated into KELM to establish a new machine learning model named DFSCA-KELM. Firstly, using the CEC2017 benchmark suite, the exploration and exploitation capabilities of DFSCA were demonstrated. Secondly, evaluation of the model DFSCA-KELM on six medical datasets extracted from the UCI machine learning repository for medical diagnosis proved the effectiveness of the proposed model. At last, the model DFSCA-KELM was applied to solve two real medical cases, and the results indicate that DFSCA-KELM can also deal with practical medical problems effectively. Taken together, these results show that the proposed technique can be regarded as a promising tool for medical diagnosis.},
  langid = {english},
  pmid = {34953358},
  keywords = {Algorithms,Benchmarking,Disperse foraging strategy,Kernel extreme learning machine,Machine Learning,Medical diagnosis,Parameter optimization,Sine cosine algorithm}
}

@article{xiongImpactCOVID19Pandemic2020,
  title = {Impact of {{COVID-19}} Pandemic on Mental Health in the General Population: {{A}} Systematic Review},
  shorttitle = {Impact of {{COVID-19}} Pandemic on Mental Health in the General Population},
  author = {Xiong, Jiaqi and Lipsitz, Orly and Nasri, Flora and Lui, Leanna M. W. and Gill, Hartej and Phan, Lee and {Chen-Li}, David and Iacobucci, Michelle and Ho, Roger and Majeed, Amna and McIntyre, Roger S.},
  year = {2020},
  month = dec,
  journal = {Journal of Affective Disorders},
  volume = {277},
  pages = {55--64},
  issn = {0165-0327},
  doi = {10.1016/j.jad.2020.08.001},
  urldate = {2023-05-29},
  abstract = {Background As a major virus outbreak in the 21st century, the Coronavirus disease 2019 (COVID-19) pandemic has led to unprecedented hazards to mental health globally. While psychological support is being provided to patients and healthcare workers, the general public's mental health requires significant attention as well. This systematic review aims to synthesize extant literature that reports on the effects of COVID-19 on psychological outcomes of the general population and its associated risk factors. Methods A systematic search was conducted on PubMed, Embase, Medline, Web of Science, and Scopus from inception to 17 May 2020 following the PRISMA guidelines. A manual search on Google Scholar was performed to identify additional relevant studies. Articles were selected based on the predetermined eligibility criteria. Results: Relatively high rates of symptoms of anxiety (6.33\% to 50.9\%), depression (14.6\% to 48.3\%), post-traumatic stress disorder (7\% to 53.8\%), psychological distress (34.43\% to 38\%), and stress (8.1\% to 81.9\%) are reported in the general population during the COVID-19 pandemic in China, Spain, Italy, Iran, the US, Turkey, Nepal, and Denmark. Risk factors associated with distress measures include female gender, younger age group ({$\leq$}40 years), presence of chronic/psychiatric illnesses, unemployment, student status, and frequent exposure to social media/news concerning COVID-19. Limitations A significant degree of heterogeneity was noted across studies. Conclusions The COVID-19 pandemic is associated with highly significant levels of psychological distress that, in many cases, would meet the threshold for clinical relevance. Mitigating the hazardous effects of COVID-19 on mental health is an international public health priority.},
  langid = {english},
  keywords = {Anxiety,COVID-19,Depression,General population,Mental health,Post-traumatic stress disorder (PTSD)},
  file = {/Users/simon/Zotero/storage/73YG3DNR/Xiong et al. - 2020 - Impact of COVID-19 pandemic on mental health in th.pdf;/Users/simon/Zotero/storage/TC3EXD8Z/S0165032720325891.html}
}

@article{yakimovichLabelsHaystackApproaches2021,
  title = {Labels in a Haystack: {{Approaches}} beyond Supervised Learning in Biomedical Applications},
  shorttitle = {Labels in a Haystack},
  author = {Yakimovich, Artur and Beaugnon, Ana{\"e}l and Huang, Yi and Ozkirimli, Elif},
  year = {2021},
  month = dec,
  journal = {Patterns},
  volume = {2},
  number = {12},
  pages = {100383},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2021.100383},
  urldate = {2023-04-24},
  abstract = {Recent advances in biomedical machine learning demonstrate great potential for data-driven techniques in health care and biomedical research. However, this potential has thus far been hampered by both the scarcity of annotated data in the biomedical domain and the diversity of the domain's subfields. While unsupervised learning is capable of finding unknown patterns in the data by design, supervised learning requires human annotation to achieve the desired performance through training. With the latter performing vastly better than the former, the need for annotated datasets is high, but they are costly and laborious to obtain. This review explores a family of approaches existing between the supervised and the unsupervised problem setting. The goal of these algorithms is to make more efficient use of the available labeled data. The advantages and limitations of each approach are addressed and perspectives are provided.},
  langid = {english},
  keywords = {active learning,data annotation,data labeling,data value,machine learning,self-supervised learning,semi-supervised learning,zero-shot learning},
  file = {/Users/simon/Zotero/storage/GDMB362D/Yakimovich et al. - 2021 - Labels in a haystack Approaches beyond supervised.pdf}
}

@article{yangAlphaFold2ItsApplications2023,
  title = {{{AlphaFold2}} and Its Applications in the Fields of Biology and Medicine},
  author = {Yang, Zhenyu and Zeng, Xiaoxi and Zhao, Yi and Chen, Runsheng},
  year = {2023},
  month = mar,
  journal = {Signal Transduction and Targeted Therapy},
  volume = {8},
  number = {1},
  pages = {1--14},
  publisher = {{Nature Publishing Group}},
  issn = {2059-3635},
  doi = {10.1038/s41392-023-01381-z},
  urldate = {2023-08-26},
  abstract = {AlphaFold2 (AF2) is an artificial intelligence (AI) system developed by DeepMind that can predict three-dimensional (3D) structures of proteins from amino acid sequences with atomic-level accuracy. Protein structure prediction is one of the most challenging problems in computational biology and chemistry, and has puzzled scientists for 50 years. The advent of AF2 presents an unprecedented progress in protein structure prediction and has attracted much attention. Subsequent release of structures of more than 200 million proteins predicted by AF2 further aroused great enthusiasm in the science community, especially in the fields of biology and medicine. AF2 is thought to have a significant impact on structural biology and research areas that need protein structure information, such as drug discovery, protein design, prediction of protein function, et al. Though the time is not long since AF2 was developed, there are already quite a few application studies of AF2 in the fields of biology and medicine, with many of them having preliminarily proved the potential of AF2. To better understand AF2 and promote its applications, we will in this article summarize the principle and system architecture of AF2 as well as the recipe of its success, and particularly focus on reviewing its applications in the fields of biology and medicine. Limitations of current AF2 prediction will also be discussed.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Structural biology},
  file = {/Users/simon/Zotero/storage/LDQFPWAS/Yang et al. - 2023 - AlphaFold2 and its applications in the fields of b.pdf}
}

@misc{yosinskiHowTransferableAre2014,
  title = {How Transferable Are Features in Deep Neural Networks?},
  author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  year = {2014},
  month = nov,
  number = {arXiv:1411.1792},
  eprint = {1411.1792},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1411.1792},
  urldate = {2023-08-30},
  abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Transferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  note = {Comment: To appear in Advances in Neural Information Processing Systems 27 (NIPS 2014)},
  file = {/Users/simon/Zotero/storage/V5ZQNR8P/Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf;/Users/simon/Zotero/storage/GWWMXQBF/1411.html}
}

@inproceedings{zhangHowRobustifyBlackBox2022,
  title = {How to {{Robustify Black-Box ML Models}}? {{A Zeroth-Order Optimization Perspective}}},
  shorttitle = {How to {{Robustify Black-Box ML Models}}?},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Zhang, Yimeng and Yao, Yuguang and Jia, Jinghan and Yi, Jinfeng and Hong, Mingyi and Chang, Shiyu and Liu, Sijia},
  year = {2022},
  month = jan,
  urldate = {2023-05-16},
  abstract = {The lack of adversarial robustness has been recognized as an important issue for state-of-the-art machine learning (ML) models, e.g., deep neural networks (DNNs). Thereby, robustifying ML models against adversarial attacks is now a major focus of research. However, nearly all existing defense methods, particularly for robust training, made the white-box assumption that the defender has the access to the details of an ML model (or its surrogate alternatives if available), e.g., its architectures and parameters. Beyond existing works, in this paper we aim to address the problem of black-box defense: How to robustify a black-box model using just input queries and output feedback? Such a problem arises in practical scenarios, where the owner of the predictive model is reluctant to share model information in order to preserve privacy. To this end, we propose a general notion of defensive operation that can be applied to black-box models, and design it through the lens of denoised smoothing (DS), a first-order (FO) certified defense technique. To allow the design of merely using model queries, we further integrate DS with the zeroth-order (gradient-free) optimization. However, a direct implementation of zeroth-order (ZO) optimization suffers a high variance of gradient estimates, and thus leads to ineffective defense. To tackle this problem, we next propose to prepend an autoencoder (AE) to a given (black-box) model so that DS can be trained using variance-reduced ZO optimization. We term the eventual defense as ZO-AE-DS. In practice, we empirically show that ZO-AE-DS can achieve improved accuracy, certified robustness, and query complexity over existing baselines. And the effectiveness of our approach is justified under both image classification and image reconstruction tasks.},
  langid = {english},
  file = {/Users/simon/Zotero/storage/FZ68N39A/Zhang et al. - 2022 - How to Robustify Black-Box ML Models A Zeroth-Ord.pdf}
}

@misc{zhuDeformableDETRDeformable2021,
  title = {Deformable {{DETR}}: {{Deformable Transformers}} for {{End-to-End Object Detection}}},
  shorttitle = {Deformable {{DETR}}},
  author = {Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  year = {2021},
  month = mar,
  number = {arXiv:2010.04159},
  eprint = {2010.04159},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2010.04159},
  urldate = {2023-08-28},
  abstract = {DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10 times less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code is released at https://github.com/fundamentalvision/Deformable-DETR.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: ICLR 2021 Oral},
  file = {/Users/simon/Zotero/storage/8A9VUX56/Zhu et al. - 2021 - Deformable DETR Deformable Transformers for End-t.pdf;/Users/simon/Zotero/storage/Y8Q6RQSG/2010.html}
}

@misc{zotero-626,
  urldate = {2023-02-06},
  howpublished = {https://wiki.xnat.org/ml},
  file = {/Users/simon/Zotero/storage/4NLN9GVT/ml.html}
}

@article{zouObjectDetection202023b,
  title = {Object {{Detection}} in 20 {{Years}}: {{A Survey}}},
  shorttitle = {Object {{Detection}} in 20 {{Years}}},
  author = {Zou, Zhengxia and Chen, Keyan and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
  year = {2023},
  month = mar,
  journal = {Proceedings of the IEEE},
  volume = {111},
  number = {3},
  pages = {257--276},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2023.3238524},
  abstract = {Object detection, as of one the most fundamental and challenging problems in computer vision, has received great attention in recent years. Over the past two decades, we have seen a rapid technological evolution of object detection and its profound impact on the entire computer vision field. If we consider today's object detection technique as a revolution driven by deep learning, then, back in the 1990s, we would see the ingenious thinking and long-term perspective design of early computer vision. This article extensively reviews this fast-moving research field in the light of technical evolution, spanning over a quarter-century's time (from the 1990s to 2022). A number of topics have been covered in this article, including the milestone detectors in history, detection datasets, metrics, fundamental building blocks of the detection system, speedup techniques, and recent state-of-the-art detection methods.},
  keywords = {Computer vision,Convolutional neural networks,convolutional neural networks (CNNs),deep learning,Deep learning,Detectors,Feature extraction,object detection,Object detection,technical evolution},
  file = {/Users/simon/Zotero/storage/3VZMVZZT/Zou et al. - 2023 - Object Detection in 20 Years A Survey.pdf}
}
