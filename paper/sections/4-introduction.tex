% \providecommand{\main}{..} 

\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../figures/}}}
\usepackage{bbm}

% \addbibresource{../bibliography/bibliography.bib} % 

\begin{document}
\chapter{Introduction}
\label{chap:intro}

	% COMENZAR A ESCRIBIR EL TRABAJO
	% \section{Background} \label{background}
% @ts-ignore
 As health information becomes increasingly digitized, machine learning (ML) algorithms play a crucial role in deriving meaningful insights from complex, multi-modal data that is often difficult to interpret by humans. 
 Conventional machine-learning approaches, however, may be inadequate in the face of rapidly evolving health technology, shifting patient needs, and the increasing availability of large amounts of uncertain and noisy data that is deemed too unreliable for use in clinical settings.

 Modern techniques aim to address these limitations by refining models in a continual loop, prioritizing data acquisition, labeling, and feedback from experts to dynamically adapt to the data stream reliably. A field of research known in the relevant literature as \textit{continual learning} (CL) \cite{parisi_continual_2019} This work explores the potential of these techniques in a medical context. 
 
 In particular, we consider the problem of developing a machine-learning platform to aid in the research of \textit{tuberculosis} (TB), an infectious disease that affects millions of people worldwide. We incorporate continual and active learning methods into this platform to improve the performance of computer vision models used to detect tuberculosis.
 
 Furthermore, the platform proposed here is meant to be integrated into a Healthcare and Data Portal that is being developed as part of an ongoing European project for the research of Tuberculosis, and it will serve as a tool to test and validate the use of machine learning models for its diagnosis. 

 As such, in an effort to research the competence of continual adaptation methods in that context, the platform incorporates a system that is designed to continually adapt to new data as it becomes available and to ease labeling efforts by prioritizing the acquisition of the most informative data samples. Including a front-end interface for the visualization of the detection, labeling, and interaction with the models.
 
 We evaluate the system's performance on a real dataset and compare it to a baseline model that doesn't use adaptation techniques.  Our results show that the use of these methods outperforms the baseline in terms of robustness and sample efficiency while maintaining a similar level of accuracy on the test set. Furthermore, the system proposed can automatically adapt to new data and improve its performance over time. 
 
 These results demonstrate the potential of incorporating these techniques into designing real-world systems for healthcare applications and other high-stake domains. The final chapter of this work includes a discussion about possible future work and improvements to the system that might facilitate its integration into other projects and a broader discussion about the potential of these techniques beyond the scope of this work.
    
 \section{Context and Motivation} \label{sec:motivation}
%  \section{An ML Platform to aid on the research of Mycobacterial Tuberculosis (TB)}
%  drug discovery and early detection of

    Tuberculosis (TB) is an infectious pulmonary disease that has affected humankind for well over 4,000 years \cite{cdctb_world_2023} and still affects millions of people worldwide. According to the World Health Organization, until the arrival of the COVID-19 pandemic, TB was the leading cause of widespread death from a single infectious agent, even above HIV \cite{who_global_2022}.


    This work is done in the context of the European Regimen Accelerator for Tuberculosis (ERA4TB). ERA4TB is a public-private initiative that started in 2020 and aims to create an open European platform to accelerate the development of new treatment regimens for tuberculosis (TB). The project is integrated by over 31 organizations from the European Union and the United States, including academic institutions, research centers, non-profit organizations, and other public and private entities \cite{noauthor_era4tb}.
    
    ERA4TB's mission statement aligns itself with (and is in response to) the United Nation's (UN) Sustainable Development Goals (SGD) to end the TB epidemic by 2030 \cite{world_health_organization_regional_office_for_europe_tuberculosis_2017}. The project's website reads, `The goal of ERA4TB is to deliver an innovative and differentiated combination regimen for the treatment of TB, which can play a key role in the TB elimination agenda' \cite{noauthor_era4tb}.

    To address some of the challenges of TB drug development and clinical trial design, one of the project's objectives from deliverable 1.15 of ERA4TB's agenda is developing a data-science-specific platform to enable the efficient use of machine learning methods from the collaborative platform. The platform is meant to be used by researchers and other project stakeholders to facilitate the use, development, and evaluation of machine-learning models that can aid in the research of TB.

    Thus, the motivation behind this work comes from the idea of incorporating novel methods into this data-science-specific platform to support researchers and collaborators in their mission to end TB by 2030. The techniques described in this work are designed to improve the performance of supervised models while prioritizing their overall robustness and reliability, aspects that are crucial in the context of healthcare applications.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{figures/ERA4TB_map.png}
        \caption{ERA4TB's Consortium of Partners and Collaborators. Source: \cite{noauthor_era4tb}}
        \label{fig:era4tb}
    \end{figure}

    \section{Background Concepts} \label{sec:background}
    
    The following section provides a brief introduction to some of the concepts and techniques that are relevant to this work. It is meant to provide the reader with the necessary high-level information to understand the context behind the ideas proposed that were used to inform every design decision and experiment conducted. For a more in-depth overview of the same concepts, the reader is referred to the literature review in Chapter \ref{chap:state_of_the_art}.

    \subsection{Tuberculosis Treatment and Diagnosis} \label{sec:tuberculosis_data}

    Tuberculosis is caused by the bacillus (bacteria) \textit{Mycobacterium tuberculosis} (MTB), which is transmitted when people who are sick with TB expel the bacteria into the air by coughing, sneezing, or spitting. The disease is preventable with the administration of a vaccine and curable with the use of antibiotics over a significant period (although drug-resistant strains of the bacteria are becoming increasingly common) \cite{who_tuberculosis_2023}.
    
    Nonetheless, the disease is often underdiagnosed and undertreated, especially in low-resource settings (i.e., developing countries, rural areas, and marginalized/impoverished communities), where the disease is more prevalent, calling for the development of more efficient and cost-effective methodologies to diagnose and treat the disease \cite{who_global_2022, imi_era4tb_2020,  who_tuberculosis_2023}.

    Some of the diagnosis techniques to detect TB include chest X-rays, sputum smear microscopy, and molecular tests. \textit{Chest X-rays} are a common procedure to diagnose any signs of tuberculosis due to the wide availability of radiology devices, but they are often inconclusive and require expert radiologists to interpret the results \cite{escalante_tuberculosis_2009}.
    
    \textit{Sputum smear microscopy} is another widely available technique that requires a trained clinician to identify the bacteria under images taken with a microscope of a patient's sputum (a mixture of saliva and mucus from the respiratory tract). 
    
    This technique is relatively inexpensive but requires a high concentration of bacteria in the sample to be effective. Additionally, studies argue that in conditions with limited resources and a significant number of samples, there have been reports of poor sample observation and quality control measures, which can result in false-negative results \cite{desikan_sputum_2013}.
    
    Molecular tests based on \textit{nucleic acid amplification} (NAATs), similar to the ones popularized to detect COVID-19, are another technique to diagnose TB. These tests identify the presence of bacilli by amplifying the genetic material of the bacteria in a patient's sputum sample (if any is present) and using a chemical solution to react to it \cite{cdc_tb_2016}. 
    
    NAATs are by far the most reliable method to diagnose TB and have the advantage of being rapid and fully automated. However, they are also expensive to produce and require specialized equipment, making them less accessible in low-resource settings \cite{albert_development_2016, maclean_advances_2020}. Indeed, a study conducted in 2018 showed that the ratio of smear microscopy tests to NAATs in countries with a high burden of TB was 6:1 \cite{cazabon_market_2018, maclean_advances_2020}.

    Each of these techniques presents its own benefits and limitations. Recently, there have been efforts to develop machine-learning models that can aid in the diagnosis of TB as a way to reduce the need (or provide a first/second opinion) for expert clinicians in the process and improve the speed and/or accuracy of the diagnosis \footnote{A literature review on the topic of TB diagnosis using ML methods is presented in section \ref{sec:ml_tuberculosis_detection}}.

    \begin{figure}
        \begin{subfigure}{130px}
          \centering
        %   \frame{
            \includegraphics[width=120px,height=120px]{chest_x_ray.png}
        %   }
        %   \caption{Chest X-Ray }
          \label{fig:chest_x_ray_example}
        \end{subfigure}%
        \begin{subfigure}{130px}
          \centering
        %   \frame{
          \includegraphics[width=120px,height=120px]{sputum_smear.png}
        %   }
        %   \caption{Sputum Smear with Tuberculosis Bacilli}
          \label{fig:sputum_smear_exmaple}
        \end{subfigure}
        \begin{subfigure}{130px}
          \centering
        %   \frame{
          \includegraphics[width=120px,height=120px]{MTB_RIF_Test.jpeg}
        %   }
        %   \caption{Example of Procedure of a Molecular Test for MTB}
          \label{fig:molecular_test_example}
        \end{subfigure}
        \caption{
            Examples of common techniques to diagnose Tuberculosis.
            Left: Chest X-ray of a patient with TB \cite{ubaidi_radiological_nodate}. Middle: Sputum smear with tuberculosis bacilli \cite{shah_ziehlneelsen_2017}. Right: Example of a molecular test for MTB \cite{boehme_rapid_2010}.
        }
        \label{fig:tuberculosis_diagnosis_examples}
    \end{figure}
    
    \subsection{Supervised and Semi-Supervised Machine-Learning} \label{sec:supervised_ml}

    Machine Learning (ML) is a subfield of Artificial Intelligence (AI) that studies the design of algorithms that can learn from data and make predictions based on it. ML algorithms are fed a set of data samples (often called the training set) and learn a function that maps the input data to a desired output. The goal is to learn a function that can generalize well to unseen data and make accurate predictions. 

    % \clearpage

    Supervised learning is a paradigm of ML where the goal is to fit a function $f: x \rightarrow \hat{y}$ that maps a given input, $x$, to a `prediction' output, $\hat{y}$, based on an available finite set of input-output pairs $(x_i, y_i)$ that are passed to a learnable model as `training' data. The function is learned by minimizing a loss function $L(y, \hat{y})$ that measures the difference between the `predicted' output and the actual one and returns a value that represents the error of the prediction, which is then used to update the model's parameters.
    
    \begin{figure}[h]
        \centering
        \resizebox*{0.9\columnwidth}{!}{
            % \hspace*{-0.5cm}
            \input{../figures/supervised_learning_tikz.tex}
        }
        \caption{Illustrative example of a supervised machine-learning pipeline.}
        \label{fig:supervised_learning}
    \end{figure}


    The most common supervised learning tasks are classification and regression, where the goal is to predict discrete and continuous outputs, respectively. Conversely, the aforementioned loss function is often defined based on the task at hand and the type of data available (e.g., cross-entropy loss for classification tasks, mean squared error for regression tasks, etc.).

    The presence of a known output (or label) for each input is what makes this paradigm `supervised'. For example, in healthcare, supervised learning might be used to predict the presence of a disease or condition based on a set of features extracted (or learned) from the patient's data. A model can be trained to predict the presence or severity of a disease based on a set of symptoms, clinical history, or imaging data.

    Besides its many benefits, the most significant disadvantage of supervised learning is that it often needs large amounts of labeled samples to produce accurate and robust results \cite{lecun_deep_2015}, 
    approaches such as \textit{semi-supervised learning} (sometimes also called weak supervision) aim to address this issue by leveraging both labeled and unlabeled data to train the model \cite{zhu_semi-supervised_2008}. 
    
    Semi-supervised learning works by using unlabeled samples to learn an intermediary representation of the data that can be used as a first step to train a supervised model. This approach is especially useful when the unlabeled data is abundant and easy to obtain, but their labels are scarce and expensive. This is often the case in some healthcare applications, where the labeling task can only be performed by professional workers, making it a costly and time-consuming task \cite{yakimovich_labels_2021,chen_study_2015, figueroa_predicting_2012}.
    
    % which is especially challenging in the healthcare field where the data is scarce, expensive to obtain, or difficult to label.
    
    In the last decade, one set of algorithms that have enabled significant advances in Machine Learning, allowing to solve very difficult problems, is \textbf{deep learning}. Deep learning is a subfield of ML that studies the design of algorithms that can learn complex representations of data by hierarchically composing simpler functions in an architecture inspired by the structure of the human brain known as `Deep Neural Networks' (DNN)  \cite{lecun_deep_2015}.
    
    \begin{figure}[H]
        \centering
        \resizebox*{0.5\columnwidth}{!}{
            % \hspace*{-0.5cm}
            \includegraphics{dnn_example_topol}
        }
        \caption{Example of a simplified neural network architecture taken from Topol et. al (2019) \cite{topol_high-performance_2019}.}
        \label{fig:dnn_example}
    \end{figure}

    % \clearpage
    \subsection{Challenges and Potential of Adopting ML-enabled Systems in Healthcare}

    ML techniques have seen their adoption in many applications, from malware and spam detection to self-driving cars and environmental modeling. The healthcare field is no exception. In the 20 years between 1995 and 2015, the FDA had approved fewer than 30 algorithms for medical use. In contrast, only in the last 5 years, the total count of new approvals has reached over \textit{10 times} that amount (see Figure \ref{fig:fda_approved_ml_apps}). 

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{fda_approved_ml_apps}
        \caption{Number of FDA-approved AI applications per year since 2005. Data Source: \cite{health_artificial_2022}}
        \label{fig:fda_approved_ml_apps}
    \end{figure}
    
    Indeed, the recent availability to store and process ever larger amounts of data through the use of Big Data technologies and the development of more powerful hardware and algorithmic techniques have made it possible to train models that can perform complex medical tasks with enough high accuracy and robustness to be considered for use
    \cite{topol_high-performance_2019}.

    Of such techniques, some that have recently disrupted the medical field are those based on \textbf{computer vision}  (CV). CV methods try to develop algorithms that enable computers to solve visual tasks. It is a broad field that has been applied to problems like image classification, object detection, and image segmentation and has seen significant advances in the last decade thanks to the adoption of Deep Learning algorithms \cite{lecun_deep_2015}.

    In the context of healthcare, CV techniques have been primarily used in radiology to aid with the diagnosis of diseases and other tasks through the analysis of medical images (e.g., X-rays, CT scans, MRIs, microscopy, etc.) \cite{esteva_deep_2021}. Indeed, over 75\% of all FDA-cleared AI applications have been for radiology use cases \cite{health_artificial_2022}.
    
    One study made in 2018 trained a \textit{Convolutional Neural Network} (CNN), a common DL model popular for computer vision tasks, to detect pneumonia from X-ray images at an Indian hospital. The researchers compared the performance of the algorithm with the findings of four expert radiologists and concluded that the algorithm was comparable to - sometimes even \textit{outperformed} - the radiologist in most cases \cite{wang_chestx-ray8_2017}.

    \clearpage

    \begin{table}[h]
       \resizebox{0.95\textwidth}{!}{
           \begin{tabular}{lrll}
               \toprule
               Company &  Year & Usecase & Panel \\
               \midrule
               Apple &  2022 & Atrial Fibrillation Detection via Apple Watch & Cardiovascular \\
               Arterys &  2022 & Liver and Lung Cancer Detection & Radiology \\
               Philips Healthcare &  2022 & Philips Incisive CT Reconstruction & Radiology \\ 
               GE Healthcare &  2021 & Deep Learning Image Reconstruction &  Radiology \\
               Siemens &  2021 & AI-Rad Companion for CT Interpretation & Radiology \\
               Icometrix &  2018 & Brain MRI Analysis & Radiology \\ 
               23\&Me &  2017 & Genetic Testing for Hereditary Thrombophilia & Hematology \\
               \bottomrule
           \end{tabular}
           \caption{Examples of FDA-approved AI applications for medical use. S\lowercase{ource: \cite{health_artificial_2022}}}
       }
   \end{table}

    Other AI systems such as Google Deepmind's \textit{AlphaFold} \cite{yang_alphafold2_2023} have been shown to predict the 3D structure of proteins with high accuracy, solving a problem that had been considered to be one of the most challenging in computational biology for over 50 years. Such breakthrough is thought to have a significant impact in applications like drug discovery in the near future \cite{jumper_highly_2021}.
    
    Results like these shine a light on the potential that AI techniques have in the medical field. However, the adoption of such technologies doesn't come with new challenges. Experts have emphasized the importance of improving aspects of these models like their lack of interpretability, robustness to unseen data, and the difficulty of integrating them into existing workflows before they can be widely adopted in clinical settings \cite{esteva_deep_2021, topol_high-performance_2019}.
    
%    \clearpage

    Thus, the design of ml-enabled systems must be mindful of the limitations of such models. Research in the healthcare and AI fields must pave the way to develop workflows that can be trusted by every stakeholder alike to improve the quality of care/research, reduce costs, and overall increase the efficiency of the healthcare system.


    \subsection{Continual Learning and Self-Adaptive Systems} \label{sec:lifelong_adaptive_systems}

    To address some of the challenges of adopting ML-enabled systems in healthcare, we can take a look at the idea of incorporating \textit{continual learning} and \textit{self-adaptive systems} (SAS) in their design. Continual learning refers to the ability of an ML system to learn continually from new data, adapting to novel changes in the data stream that it may have not been exposed to before \cite{parisi_continual_2019}. 
    
    SAS has a similar definition, but it generalizes to any software systems that continually monitor faults in their operating environment using a closed feedback loop. The system can then modify its behavior at runtime by the execution of so-called \textbf{tactics} in an attempt to fix them, thereby reducing human efforts in the interaction. Nowadays, self-adaptivity is considered a classical concept with ample literature in fields like software engineering and robotics \cite{macias-escrivaSelfadaptiveSystemsSurvey2013,gheibiApplyingMachineLearning2020,casimiro_self-adaptive_2022}.

    \clearpage
    
    The two ideas are closely related, with \textit{continual} (or \textit{lifelong}) learning often used to refer specifically to ML systems while \textit{SAS} to any software that adapts itself to disruptive changes. The core idea of both is the same, though, the ability of a system to `survive' variations in its environment with or without human intervention and continue to perform its intended function \cite{macias-escrivaSelfadaptiveSystemsSurvey2013}. 
    
    In this work, we use the term \textbf{continually adaptative machine learning} to refer to this idea applied to ML models - drawing inspiration from both concepts. 

    Consider the scenario of a machine-learning model that has been trained with pictures from an X-ray machine of a particular hospital. The model is then deployed in a different hospital where the X-ray machines are of another and produce images with different characteristics (a particular noise, artifacts, different resolution, etc.). 
    
    Because the data distribution is different from the one the model was trained with, the model's performance may likely be affected. However, under a continual learning setting, the model would be able to adapt to the new data and improve its performance over time. 

    % SAS often adopt a feedback-loop architecture known as \textbf{MAPE-K} loops. These systems are based on using some form of \textit{knowledge-base} to continually \textit{monitor} the system, to then evaluate when an \textit{adaptation} is needed, to finally select the best action \textit{plan} and \textit{execute} it (The letters in MAPE stand for the words Monitor, Analyze, Plan, and Execute, and the K stands for Knowledge) \cite{redbooks_practical_2004}.
    
    On the other side, the design of such systems in practice presents unique challenges that must be addressed - the FDA has never approved a medical application based on continual learning, experts argue that this is owing to the fact of questionable robustness of the adaptation process \cite{vokingerContinualLearningMedical2021}. 
    
    Indeed, some known problems like \textit{catastrophic forgetting} (i.e., when the model forgets how to perform a task after learning a new one) and \textit{bias drift} (i.e., when the model's predictions suddenly become biased towards a particular class or group of samples) are among the most studied phenomena in continual learning.
    
    % In particular, ML models differ from traditional software systems in that they are often trained on a fixed dataset but deployed in a dynamic environment 
    
    Still, the fact that ML models are often deployed as static components in a dynamic environment with the assumption that the data used to train them is representative of the data it will encounter in the real world is a known source of degradation \cite{vokingerContinualLearningMedical2021}.

    Table \ref{tab:causes_of_ml_degradation} describes some of the most relevant causes of degradation of ML systems. It gives an overview of different phenomena that can affect a model's performance and the challenges that must be addressed in the design of an adaptive system.

    \begin{table}[t]
        \caption{Some causes of Degradation of an ML System and their characteristics.}
        \label{tab:causes_of_ml_degradation}
        \resizebox{\textwidth}{!}{
        \begin{tabular}{p{0.22\linewidth} | p{0.42\linewidth} | p{0.41\linewidth}}
        \toprule
        \textbf{Cause} & \textbf{Description} & \textbf{Example} \\
        \midrule
            \multirow{3}{*}{\small \textbf{Data Drift}} & \footnotesize
            \textbf{Covariate shift:} When the input distribution $P(X)$ that the model was trained with differs significantly from the one in the inference environment (i.e. the input changes over time, but the model remains the same). &
            \footnotesize
            A model trained on chest X-ray images from a particular dataset is deployed in a hospital where the X-ray machines are of a different brand and produce images with different characteristics.
            \\
            \cline{2-3} & \footnotesize
            \textbf{Label shift:} When the model is trained on a dataset whose class proportions are substantially different from the ones in the inference environment ($P(Y)$). &
            \footnotesize
            A model trained on a dataset where the proportion of positive cases is 50\% is deployed in a hospital where the proportion is 10\%. \\
        \midrule
        \multirow{2}{*}{\small \textbf{Model Unfairness}} & \footnotesize
            \textbf{Model bias:} The model misrepresents or produces an erroneous causal relationship between its input features and the target output, often caused when the training data is not fully representative of the real-word. & 
            \footnotesize
            A model trained with data from patients of a hospital in one neighborhood performs poorly after being deployed in another neighborhood with very different demographics. \\
            % \cline{2-3} & \footnotesize
        \midrule
        \multirow{2}{*}{\small \textbf{Learning Plasticity}} & \footnotesize
            \textbf{Catastrophic forgetting:} The model no longer performs well in an old task after training on new information. & \footnotesize  
            A model is trained to detect a specific disease, but when adapted to detect a different disease, it `forgets' how to detect the first.\\
            \cline{2-3} & \footnotesize
            \textbf{Loss of Plasticity:} The model is unable to learn new information after training on a specific task (DNNs are often prone to this phenomenon \cite{parisi_continual_2019}).
            & \footnotesize
            A model is trained to detect a specific disease, but can't be adapted to detect a different one. \\
        \midrule
            \small \textbf{Adversarial Attacks} & \footnotesize
            \textbf{Vulnerability to adversarial attacks:}  The model is vulnerable to small perturbations to the input that cause it to make very different predictions than it would otherwise.
            & \footnotesize
            A bad actor makes imperceptible changes to individual pixels in an X-ray image that cause the model to misclassify the presence of a disease. \\
        \bottomrule
        \end{tabular}
    }
    \end{table}
    % \vspace*{-0.5cm}

    One important thing to note is that a model experiencing one of the degradation causes listed doesn't mean that it will necessarily fail or that it should be addressed. For example, a model might suffer from catastrophic forgetting after learning new information but that might not affect the performance of the current task in any significant way.
    
    This is why a crucial aspect of designing such systems is that of defining the \textit{adaptation criteria} that should be monitored in order to trigger the right \textit{tactics} that will allow the system to adapt to the specific changes in its environment that cause it to degrade.
    
    % This criterion should be based on the specific needs of the application and the context in which the system is deployed. An example is that a model trained to detect a specific rare disease might have different criteria than a model trained to detect a more common one (e.g. The first system might be more sensitive to data drift than the latter).

    In chapter \ref{chap:state_of_the_art} we address some state-of-the-art techniques that can be used to deal with the causes of degradation listed in the table. 
    % In particular, we will focus on the techniques that have been proposed to address the challenges of data drift and model degradation, as these are the most relevant to the context of this work.

    \section{Objectives} \label{sec:objectives}

    \subsection*{Main objective} \label{sec:main_goal}

    The main objective of this work is to research the most relevant techniques on continual adaptation methods in Machine Learning, make a comparative analysis of the most relevant techniques and their relevance for health applications, and design and implement a system for the diagnosis of tuberculosis that incorporates these techniques into its design that can be integrated into the ERA4TB platform. 
    
    The platform should allow its users to incorporate machine-learning models into the platform, facilitate their use, and allow collaboration between researchers and other stakeholders.

    \subsection*{Specific objectives} \label{sec:specific_objectives}

    Auxiliary to the main objective, the following specific objectives have been defined to guide the development of the work and evaluate its success:

    \begin{enumerate}
        \item The system should be capable of automatically triggering the continual learning process when new data is available or when the model's performance degrades based on a predefined metric.
        \item The platform must implement a feedback loop between the data annotation process and model training that prioritizes the acquisition of the most informative data samples to improve the model's performance (Active Learning).
        \item Develop a front-end interface that allows users to interact with the machine-learning models by selecting or submitting new data samples and visualizing the model's predictions.
        \item Consider the limitations of the proposed system and the ethical implications of its use and present a well-founded outline of necessary future work to address these limitations or improve the system in a way that aligns with the project's mission statement.
        \item Evaluate possible future research directions that could be explored in the area of continual and dynamic adaptation in Machine Learning, highlighting the contributions that have a higher potential for impact in healthcare or other high-stake domains.
    \end{enumerate}

    % \clearpage

    % \section{Main Contributions} \label{sec:main_contributions}

    \section{Structure of the Work} \label{sec:structure_of_the_work}

    This work is divided into five chapters, including this introduction. Chapter \ref{chap:intro} describes the context and motivation of this work and its objectives and provides the necessary background information to understand the concepts and techniques used. 
    
    Chapter \ref{chap:state_of_the_art} describes relevant work and state-of-the-art techniques. It also provides a literature review of related work in tuberculosis detection and adaptive machine learning systems, highlighting the most important contributions and their limitations and showing examples of their use in healthcare applications.

    Chapter \ref{chap:methodology} describes the methodology used to design and implement the proposed system.  It gives a detailed description of the data, models, techniques, and specific tools used in the implementation of the platform, experiments conducted, and relevant metrics to evaluate the system's performance.
    
    Chapter \ref{chap:results} presents the results of the experiments described in the previous chapter, analyzing the performance of the system, and comparing the results with the baseline metrics.
    
    Finally, Chapter \ref{chap:conclusions} presents the conclusions of the work. It discusses the implications of the results obtained in the context of the project and the limitations of the proposed system. It also proposes possible future work that could be explored to improve the system and its integration into the ERA4TB platform and discusses emergent directions in the areas of research discussed in this work, highlighting those that have a higher potential for impact or that we consider to be of special interest.

    Additionally, there are two extra chapters at the end where we discuss the regulatory framework, ethical considerations, and the socioeconomic implications of the use of the proposed system (or similar systems) in the context of the project and the healthcare field in general.
    

% \dobib
\end{document}